{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Matthew-Jennings/mech-interp-explore/blob/main/capital_letter_follows_full_stop_CONTINUED.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does GPT-2 Small Predict Capital Letters After Full Stops? - *Exploratory Analysis*\n",
    "### Matthew Jennings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from pprint import pprint\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "import einops\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import torch\n",
    "from circuitsvis.attention import attention_heads\n",
    "from fancy_einsum import einsum\n",
    "from IPython.display import HTML, IFrame\n",
    "from jaxtyping import Float\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens import ActivationCache, HookedTransformer\n",
    "\n",
    "from helpers import cumul_probs_by_capitalisation_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We turn automatic differentiation off, to save GPU memory, as this notebook focuses on model inference not model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x28103ebb290>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define plotting helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(tensor, **kwargs):\n",
    "    px.imshow(\n",
    "        utils.to_numpy(tensor),\n",
    "        color_continuous_midpoint=0.0,\n",
    "        color_continuous_scale=\"RdBu\",\n",
    "        **kwargs,\n",
    "    ).show()\n",
    "\n",
    "\n",
    "def line(tensor, **kwargs):\n",
    "    px.line(\n",
    "        y=utils.to_numpy(tensor),\n",
    "        **kwargs,\n",
    "    ).show()\n",
    "\n",
    "\n",
    "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", **kwargs):\n",
    "    x = utils.to_numpy(x)\n",
    "    y = utils.to_numpy(y)\n",
    "    px.scatter(\n",
    "        y=y,\n",
    "        x=x,\n",
    "        labels={\"x\": xaxis, \"y\": yaxis, \"color\": caxis},\n",
    "        **kwargs,\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "Pytorch device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matth\\Workspace\\arena3\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1150: UserWarning: expandable_segments not supported on this platform (Triggered internally at ..\\c10/cuda/CUDAAllocatorConfig.h:30.)\n",
      "  return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\n",
    "    \"gpt2-small\",\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    refactor_factored_attn_matrices=True,\n",
    ")\n",
    "\n",
    "# Get the default device used\n",
    "device: torch.device = utils.get_device()\n",
    "print(f\"Pytorch device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple first example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the model correctly predict capital letters after a full stop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<|endoftext|>', 'This', ' is', ' a', ' sentence', '.']\n",
      "Tokenized answer: [' It']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15.14</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.67</span><span style=\"font-weight: bold\">% Token: | It|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m15.14\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m10.67\u001b[0m\u001b[1m% Token: | It|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 15.64 Prob: 17.54% Token: |\n",
      "|\n",
      "Top 1th token. Logit: 15.14 Prob: 10.67% Token: | It|\n",
      "Top 2th token. Logit: 14.47 Prob:  5.44% Token: | This|\n",
      "Top 3th token. Logit: 14.39 Prob:  5.03% Token: | I|\n",
      "Top 4th token. Logit: 14.37 Prob:  4.94% Token: | The|\n",
      "Top 5th token. Logit: 14.09 Prob:  3.75% Token: | If|\n",
      "Top 6th token. Logit: 14.07 Prob:  3.68% Token: | A|\n",
      "Top 7th token. Logit: 13.80 Prob:  2.79% Token: | You|\n",
      "Top 8th token. Logit: 13.26 Prob:  1.63% Token: | Please|\n",
      "Top 9th token. Logit: 12.99 Prob:  1.25% Token: | We|\n",
      "Top 10th token. Logit: 12.97 Prob:  1.22% Token: | In|\n",
      "Top 11th token. Logit: 12.87 Prob:  1.10% Token: | There|\n",
      "Top 12th token. Logit: 12.83 Prob:  1.06% Token: |\n",
      "\n",
      "|\n",
      "Top 13th token. Logit: 12.71 Prob:  0.94% Token: | For|\n",
      "Top 14th token. Logit: 12.66 Prob:  0.90% Token: | An|\n",
      "Top 15th token. Logit: 12.45 Prob:  0.73% Token: | See|\n",
      "Top 16th token. Logit: 12.38 Prob:  0.67% Token: |<|endoftext|>|\n",
      "Top 17th token. Logit: 12.26 Prob:  0.60% Token: | \"|\n",
      "Top 18th token. Logit: 12.24 Prob:  0.59% Token: | To|\n",
      "Top 19th token. Logit: 12.19 Prob:  0.56% Token: | As|\n",
      "Top 20th token. Logit: 12.13 Prob:  0.53% Token: | Read|\n",
      "Top 21th token. Logit: 12.02 Prob:  0.47% Token: | When|\n",
      "Top 22th token. Logit: 11.98 Prob:  0.46% Token: | Do|\n",
      "Top 23th token. Logit: 11.98 Prob:  0.45% Token: | That|\n",
      "Top 24th token. Logit: 11.94 Prob:  0.44% Token: | Let|\n",
      "Top 25th token. Logit: 11.93 Prob:  0.43% Token: | (|\n",
      "Top 26th token. Logit: 11.93 Prob:  0.43% Token: | No|\n",
      "Top 27th token. Logit: 11.86 Prob:  0.40% Token: | Your|\n",
      "Top 28th token. Logit: 11.82 Prob:  0.39% Token: | And|\n",
      "Top 29th token. Logit: 11.78 Prob:  0.37% Token: | What|\n",
      "Top 30th token. Logit: 11.75 Prob:  0.36% Token: | Don|\n",
      "Top 31th token. Logit: 11.67 Prob:  0.33% Token: | Here|\n",
      "Top 32th token. Logit: 11.53 Prob:  0.29% Token: | But|\n",
      "Top 33th token. Logit: 11.49 Prob:  0.28% Token: | All|\n",
      "Top 34th token. Logit: 11.47 Prob:  0.27% Token: | Be|\n",
      "Top 35th token. Logit: 11.46 Prob:  0.27% Token: | So|\n",
      "Top 36th token. Logit: 11.38 Prob:  0.25% Token: | Click|\n",
      "Top 37th token. Logit: 11.38 Prob:  0.25% Token: | Just|\n",
      "Top 38th token. Logit: 11.37 Prob:  0.25% Token: | Not|\n",
      "Top 39th token. Logit: 11.29 Prob:  0.23% Token: | Some|\n",
      "Top 40th token. Logit: 11.25 Prob:  0.22% Token: | Like|\n",
      "Top 41th token. Logit: 11.25 Prob:  0.22% Token: | One|\n",
      "Top 42th token. Logit: 11.23 Prob:  0.21% Token: | Go|\n",
      "Top 43th token. Logit: 11.21 Prob:  0.21% Token: | Each|\n",
      "Top 44th token. Logit: 11.20 Prob:  0.21% Token: | My|\n",
      "Top 45th token. Logit: 11.20 Prob:  0.21% Token: | First|\n",
      "Top 46th token. Logit: 11.14 Prob:  0.20% Token: | He|\n",
      "Top 47th token. Logit: 11.05 Prob:  0.18% Token: | Write|\n",
      "Top 48th token. Logit: 11.05 Prob:  0.18% Token: | Every|\n",
      "Top 49th token. Logit: 11.05 Prob:  0.18% Token: | Remember|\n",
      "Top 50th token. Logit: 11.02 Prob:  0.17% Token: | Take|\n",
      "Top 51th token. Logit: 11.02 Prob:  0.17% Token: | These|\n",
      "Top 52th token. Logit: 11.02 Prob:  0.17% Token: | Try|\n",
      "Top 53th token. Logit: 11.00 Prob:  0.17% Token: | Any|\n",
      "Top 54th token. Logit: 10.98 Prob:  0.17% Token: | While|\n",
      "Top 55th token. Logit: 10.98 Prob:  0.17% Token: | Its|\n",
      "Top 56th token. Logit: 10.98 Prob:  0.17% Token: | Because|\n",
      "Top 57th token. Logit: 10.97 Prob:  0.17% Token: | Think|\n",
      "Top 58th token. Logit: 10.89 Prob:  0.15% Token: | At|\n",
      "Top 59th token. Logit: 10.87 Prob:  0.15% Token: | After|\n",
      "Top 60th token. Logit: 10.79 Prob:  0.14% Token: | On|\n",
      "Top 61th token. Logit: 10.78 Prob:  0.14% Token: | Yes|\n",
      "Top 62th token. Logit: 10.75 Prob:  0.13% Token: | Get|\n",
      "Top 63th token. Logit: 10.75 Prob:  0.13% Token: | Feel|\n",
      "Top 64th token. Logit: 10.75 Prob:  0.13% Token: | Use|\n",
      "Top 65th token. Logit: 10.74 Prob:  0.13% Token: | By|\n",
      "Top 66th token. Logit: 10.73 Prob:  0.13% Token: | Make|\n",
      "Top 67th token. Logit: 10.72 Prob:  0.13% Token: | Or|\n",
      "Top 68th token. Logit: 10.71 Prob:  0.13% Token: | Although|\n",
      "Top 69th token. Logit: 10.71 Prob:  0.13% Token: | Have|\n",
      "Top 70th token. Logit: 10.69 Prob:  0.13% Token: | Find|\n",
      "Top 71th token. Logit: 10.69 Prob:  0.13% Token: | Once|\n",
      "Top 72th token. Logit: 10.69 Prob:  0.13% Token: | Words|\n",
      "Top 73th token. Logit: 10.66 Prob:  0.12% Token: | Nothing|\n",
      "Top 74th token. Logit: 10.64 Prob:  0.12% Token: | Sometimes|\n",
      "Top 75th token. Logit: 10.62 Prob:  0.12% Token: | Look|\n",
      "Top 76th token. Logit: 10.62 Prob:  0.12% Token: | Now|\n",
      "Top 77th token. Logit: 10.60 Prob:  0.11% Token: | From|\n",
      "Top 78th token. Logit: 10.57 Prob:  0.11% Token: | How|\n",
      "Top 79th token. Logit: 10.57 Prob:  0.11% Token: | [|\n",
      "Top 80th token. Logit: 10.55 Prob:  0.11% Token: | Learn|\n",
      "Top 81th token. Logit: 10.53 Prob:  0.11% Token: | Sorry|\n",
      "Top 82th token. Logit: 10.53 Prob:  0.11% Token: | Only|\n",
      "Top 83th token. Logit: 10.51 Prob:  0.10% Token: | Many|\n",
      "Top 84th token. Logit: 10.50 Prob:  0.10% Token: | Most|\n",
      "Top 85th token. Logit: 10.49 Prob:  0.10% Token: | Thank|\n",
      "Top 86th token. Logit: 10.44 Prob:  0.10% Token: | Note|\n",
      "Top 87th token. Logit: 10.41 Prob:  0.09% Token: | However|\n",
      "Top 88th token. Logit: 10.39 Prob:  0.09% Token: | Keep|\n",
      "Top 89th token. Logit: 10.39 Prob:  0.09% Token: | Follow|\n",
      "Top 90th token. Logit: 10.39 Prob:  0.09% Token: | Our|\n",
      "Top 91th token. Logit: 10.38 Prob:  0.09% Token: | Why|\n",
      "Top 92th token. Logit: 10.37 Prob:  0.09% Token: | Even|\n",
      "Top 93th token. Logit: 10.35 Prob:  0.09% Token: | Also|\n",
      "Top 94th token. Logit: 10.35 Prob:  0.09% Token: | Someone|\n",
      "Top 95th token. Logit: 10.32 Prob:  0.09% Token: | They|\n",
      "Top 96th token. Logit: 10.29 Prob:  0.08% Token: | Unless|\n",
      "Top 97th token. Logit: 10.27 Prob:  0.08% Token: | Is|\n",
      "Top 98th token. Logit: 10.25 Prob:  0.08% Token: | Something|\n",
      "Top 99th token. Logit: 10.23 Prob:  0.08% Token: | Perhaps|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' It'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' It'\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_prompt = \"This is a sentence.\"\n",
    "answer = \" It\"\n",
    "\n",
    "utils.test_prompt(example_prompt, answer, model, top_k=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "- Interesting! The top result is a newline. Inspecting the rest of the results provides a nice reminder that tokens of the form `<space><capital-letter>` *are not only valid tokens to follow a full stop.* Other examples include:\n",
    "  - `\"\\n\"`\n",
    "  - `\"\\n\\n\"`\n",
    "  - `\"<|endoftext|>\"`\n",
    "  - Non-alphanumeric chars (preceded by spaces): ` (`, ` \"`\n",
    "\n",
    "- No numeric tokens are present. I expect logits for numerical tokens to increase for if the last character preceding the full stop was numeric. Quickly test below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Space, Upper': tensor(0.7778, device='cuda:0'), 'Space, Lower': tensor(0.0032, device='cuda:0'), 'Space, Numeral': tensor(0.0023, device='cuda:0'), 'No Space, Upper': tensor(0.0035, device='cuda:0'), 'No Space, Lower': tensor(0.0010, device='cuda:0'), 'No Space, Numeral': tensor(0.0003, device='cuda:0'), 'Other': tensor(0.2119, device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "logits, _ = model.run_with_cache(example_prompt, remove_batch_dim=True)\n",
    "pprint(cumul_probs_by_capitalisation_type(logits[:, -1], model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<|endoftext|>', 'The', ' probability', ' of', ' me', ' getting', ' to', ' the', ' bottom', ' of', ' this', ' circuit', ' is', ' not', ' 0', '.']\n",
      "Tokenized answer: [' It']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15.33</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.20</span><span style=\"font-weight: bold\">% Token: | It|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m9\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m15.33\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m2.20\u001b[0m\u001b[1m% Token: | It|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 16.66 Prob:  8.34% Token: |\n",
      "|\n",
      "Top 1th token. Logit: 16.62 Prob:  7.99% Token: |5|\n",
      "Top 2th token. Logit: 16.19 Prob:  5.20% Token: |1|\n",
      "Top 3th token. Logit: 15.69 Prob:  3.16% Token: |01|\n",
      "Top 4th token. Logit: 15.61 Prob:  2.91% Token: | The|\n",
      "Top 5th token. Logit: 15.59 Prob:  2.87% Token: |001|\n",
      "Top 6th token. Logit: 15.58 Prob:  2.84% Token: |0001|\n",
      "Top 7th token. Logit: 15.56 Prob:  2.77% Token: | If|\n",
      "Top 8th token. Logit: 15.55 Prob:  2.76% Token: |0|\n",
      "Top 9th token. Logit: 15.33 Prob:  2.20% Token: | It|\n",
      "Top 10th token. Logit: 15.13 Prob:  1.81% Token: |9|\n",
      "Top 11th token. Logit: 15.08 Prob:  1.72% Token: | But|\n",
      "Top 12th token. Logit: 14.95 Prob:  1.51% Token: |000|\n",
      "Top 13th token. Logit: 14.95 Prob:  1.51% Token: |6|\n",
      "Top 14th token. Logit: 14.94 Prob:  1.49% Token: |2|\n",
      "Top 15th token. Logit: 14.87 Prob:  1.39% Token: |25|\n",
      "Top 16th token. Logit: 14.81 Prob:  1.32% Token: |05|\n",
      "Top 17th token. Logit: 14.81 Prob:  1.32% Token: |8|\n",
      "Top 18th token. Logit: 14.81 Prob:  1.31% Token: | I|\n",
      "Top 19th token. Logit: 14.80 Prob:  1.30% Token: |00|\n",
      "Top 20th token. Logit: 14.72 Prob:  1.21% Token: |7|\n",
      "Top 21th token. Logit: 14.66 Prob:  1.13% Token: |0000|\n",
      "Top 22th token. Logit: 14.66 Prob:  1.13% Token: |3|\n",
      "Top 23th token. Logit: 14.53 Prob:  1.00% Token: | This|\n",
      "Top 24th token. Logit: 14.52 Prob:  0.98% Token: |75|\n",
      "Top 25th token. Logit: 14.51 Prob:  0.97% Token: | However|\n",
      "Top 26th token. Logit: 14.49 Prob:  0.95% Token: |4|\n",
      "Top 27th token. Logit: 14.42 Prob:  0.89% Token: | You|\n",
      "Top 28th token. Logit: 14.32 Prob:  0.80% Token: |99|\n",
      "Top 29th token. Logit: 14.26 Prob:  0.76% Token: | In|\n",
      "Top 30th token. Logit: 14.12 Prob:  0.66% Token: | That|\n",
      "Top 31th token. Logit: 14.07 Prob:  0.63% Token: |000000|\n",
      "Top 32th token. Logit: 13.95 Prob:  0.55% Token: | There|\n",
      "Top 33th token. Logit: 13.90 Prob:  0.53% Token: |9999|\n",
      "Top 34th token. Logit: 13.88 Prob:  0.52% Token: |02|\n",
      "Top 35th token. Logit: 13.88 Prob:  0.52% Token: |002|\n",
      "Top 36th token. Logit: 13.78 Prob:  0.47% Token: |00000000|\n",
      "Top 37th token. Logit: 13.75 Prob:  0.46% Token: |005|\n",
      "Top 38th token. Logit: 13.72 Prob:  0.44% Token: | So|\n",
      "Top 39th token. Logit: 13.59 Prob:  0.39% Token: |\n",
      "\n",
      "|\n",
      "Top 40th token. Logit: 13.56 Prob:  0.38% Token: |50|\n",
      "Top 41th token. Logit: 13.55 Prob:  0.37% Token: |10|\n",
      "Top 42th token. Logit: 13.48 Prob:  0.35% Token: | A|\n",
      "Top 43th token. Logit: 13.47 Prob:  0.35% Token: | For|\n",
      "Top 44th token. Logit: 13.42 Prob:  0.33% Token: |06|\n",
      "Top 45th token. Logit: 13.37 Prob:  0.31% Token: | We|\n",
      "Top 46th token. Logit: 13.34 Prob:  0.30% Token: |04|\n",
      "Top 47th token. Logit: 13.33 Prob:  0.30% Token: |999|\n",
      "Top 48th token. Logit: 13.28 Prob:  0.28% Token: |09|\n",
      "Top 49th token. Logit: 13.26 Prob:  0.28% Token: | Therefore|\n",
      "Top 50th token. Logit: 13.24 Prob:  0.27% Token: |<|endoftext|>|\n",
      "Top 51th token. Logit: 13.23 Prob:  0.27% Token: | As|\n",
      "Top 52th token. Logit: 13.21 Prob:  0.27% Token: |95|\n",
      "Top 53th token. Logit: 13.14 Prob:  0.25% Token: | (|\n",
      "Top 54th token. Logit: 13.14 Prob:  0.25% Token: | And|\n",
      "Top 55th token. Logit: 13.07 Prob:  0.23% Token: |07|\n",
      "Top 56th token. Logit: 13.05 Prob:  0.23% Token: |08|\n",
      "Top 57th token. Logit: 13.04 Prob:  0.22% Token: |03|\n",
      "Top 58th token. Logit: 13.02 Prob:  0.22% Token: |15|\n",
      "Top 59th token. Logit: 13.00 Prob:  0.22% Token: | One|\n",
      "Top 60th token. Logit: 12.95 Prob:  0.20% Token: |0000000000000000|\n",
      "Top 61th token. Logit: 12.94 Prob:  0.20% Token: |35|\n",
      "Top 62th token. Logit: 12.88 Prob:  0.19% Token: |33|\n",
      "Top 63th token. Logit: 12.87 Prob:  0.19% Token: |85|\n",
      "Top 64th token. Logit: 12.84 Prob:  0.18% Token: | When|\n",
      "Top 65th token. Logit: 12.83 Prob:  0.18% Token: |500|\n",
      "Top 66th token. Logit: 12.82 Prob:  0.18% Token: |0002|\n",
      "Top 67th token. Logit: 12.82 Prob:  0.18% Token: |618|\n",
      "Top 68th token. Logit: 12.82 Prob:  0.18% Token: |45|\n",
      "Top 69th token. Logit: 12.77 Prob:  0.17% Token: |025|\n",
      "Top 70th token. Logit: 12.76 Prob:  0.17% Token: | To|\n",
      "Top 71th token. Logit: 12.76 Prob:  0.17% Token: | What|\n",
      "Top 72th token. Logit: 12.75 Prob:  0.17% Token: | On|\n",
      "Top 73th token. Logit: 12.73 Prob:  0.16% Token: | 1|\n",
      "Top 74th token. Logit: 12.73 Prob:  0.16% Token: |00000|\n",
      "Top 75th token. Logit: 12.70 Prob:  0.16% Token: |97|\n",
      "Top 76th token. Logit: 12.69 Prob:  0.16% Token: |007|\n",
      "Top 77th token. Logit: 12.69 Prob:  0.16% Token: |67|\n",
      "Top 78th token. Logit: 12.60 Prob:  0.14% Token: | At|\n",
      "Top 79th token. Logit: 12.58 Prob:  0.14% Token: |12|\n",
      "Top 80th token. Logit: 12.53 Prob:  0.13% Token: |13|\n",
      "Top 81th token. Logit: 12.51 Prob:  0.13% Token: | Even|\n",
      "Top 82th token. Logit: 12.50 Prob:  0.13% Token: |006|\n",
      "Top 83th token. Logit: 12.48 Prob:  0.13% Token: | No|\n",
      "Top 84th token. Logit: 12.46 Prob:  0.12% Token: | Not|\n",
      "Top 85th token. Logit: 12.45 Prob:  0.12% Token: | .|\n",
      "Top 86th token. Logit: 12.44 Prob:  0.12% Token: | Then|\n",
      "Top 87th token. Logit: 12.44 Prob:  0.12% Token: |11|\n",
      "Top 88th token. Logit: 12.44 Prob:  0.12% Token: |49|\n",
      "Top 89th token. Logit: 12.41 Prob:  0.12% Token: |003|\n",
      "Top 90th token. Logit: 12.37 Prob:  0.11% Token: |37|\n",
      "Top 91th token. Logit: 12.37 Prob:  0.11% Token: | Because|\n",
      "Top 92th token. Logit: 12.34 Prob:  0.11% Token: | By|\n",
      "Top 93th token. Logit: 12.31 Prob:  0.11% Token: | Of|\n",
      "Top 94th token. Logit: 12.28 Prob:  0.10% Token: |20|\n",
      "Top 95th token. Logit: 12.28 Prob:  0.10% Token: |77|\n",
      "Top 96th token. Logit: 12.24 Prob:  0.10% Token: |27|\n",
      "Top 97th token. Logit: 12.23 Prob:  0.10% Token: |100|\n",
      "Top 98th token. Logit: 12.21 Prob:  0.10% Token: |87|\n",
      "Top 99th token. Logit: 12.21 Prob:  0.10% Token: |30|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' It'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' It'\u001b[0m, \u001b[1;36m9\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "numeric_example_prompt = (\n",
    "    \"The probability of me getting to the bottom of this circuit is not 0.\"\n",
    ")\n",
    "numeric_answer = \" It\"\n",
    "\n",
    "utils.test_prompt(numeric_example_prompt, numeric_answer, model, top_k=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "- Top token is `5`! No preceding space. (Upon reruns, sometimes it is second after `\"\\n\"`\")\n",
    "- Of the top 20 predictions, only 5 are non-numeric (one of which is a newline).\n",
    "\n",
    "- Will need to consider this in circuit exploration\n",
    "  - Possibly (likely?) a different circuit handles decimal points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<|endoftext|>', 'this', ' is', ' an', ' unc', 'ap', 'ital', 'ised', ' sentence', '.']\n",
      "Tokenized answer: [' It']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10.69</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.81</span><span style=\"font-weight: bold\">% Token: | It|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m3\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m10.69\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m2.81\u001b[0m\u001b[1m% Token: | It|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 12.34 Prob: 14.65% Token: |\n",
      "|\n",
      "Top 1th token. Logit: 11.46 Prob:  6.12% Token: | I|\n",
      "Top 2th token. Logit: 10.95 Prob:  3.66% Token: |\n",
      "\n",
      "|\n",
      "Top 3th token. Logit: 10.69 Prob:  2.81% Token: | It|\n",
      "Top 4th token. Logit: 10.68 Prob:  2.81% Token: | it|\n",
      "Top 5th token. Logit: 10.64 Prob:  2.69% Token: | the|\n",
      "Top 6th token. Logit: 10.49 Prob:  2.32% Token: | i|\n",
      "Top 7th token. Logit: 10.35 Prob:  2.01% Token: | The|\n",
      "Top 8th token. Logit: 10.18 Prob:  1.69% Token: | This|\n",
      "Top 9th token. Logit: 10.07 Prob:  1.52% Token: | if|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' It'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' It'\u001b[0m, \u001b[1;36m3\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uncapitalised_example_prompt = (\n",
    "    \"this is an uncapitalised sentence.\"\n",
    ")\n",
    "uncapitalised_answer = \" It\"\n",
    "\n",
    "utils.test_prompt(uncapitalised_example_prompt, uncapitalised_answer, model, top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple examples - stick with English prose for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"Go.\",\n",
    "    \"Hello.\",\n",
    "    \"Matthew doesn't know what he is doing.\",\n",
    "    \"This is a sentence. This is another sentence.\",\n",
    "    \"The enigmatic, silver-haired professor, known for his eccentric lectures on quantum entanglement and the nature of reality, embarked on a perilous journey through the mist-shrouded mountains of Bhutan, seeking an ancient, mystical artifact rumored to hold the key to unlocking the secrets of the universe, while his loyal assistant, a quick-witted and resourceful graduate student with a penchant for solving cryptic puzzles, followed close behind, armed only with a weathered journal, a compass, and an unwavering determination to unravel the mystery that had haunted her mentor for decades.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model and get logits and cache for prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 116, 50257])\n",
      "torch.Size([5, 50257])\n",
      "Prompt length: 3\n",
      "Prompt as tokens: ['<|endoftext|>', 'Go', '.']\n",
      "Prompt length: 3\n",
      "Prompt as tokens: ['<|endoftext|>', 'Hello', '.']\n",
      "Prompt length: 10\n",
      "Prompt as tokens: ['<|endoftext|>', 'Matthew', ' doesn', \"'t\", ' know', ' what', ' he', ' is', ' doing', '.']\n",
      "Prompt length: 11\n",
      "Prompt as tokens: ['<|endoftext|>', 'This', ' is', ' a', ' sentence', '.', ' This', ' is', ' another', ' sentence', '.']\n",
      "Prompt length: 116\n",
      "Prompt as tokens: ['<|endoftext|>', 'The', ' enigmatic', ',', ' silver', '-', 'haired', ' professor', ',', ' known', ' for', ' his', ' eccentric', ' lectures', ' on', ' quantum', ' ent', 'ang', 'lement', ' and', ' the', ' nature', ' of', ' reality', ',', ' embarked', ' on', ' a', ' perilous', ' journey', ' through', ' the', ' mist', '-', 'sh', 'roud', 'ed', ' mountains', ' of', ' Bh', 'utan', ',', ' seeking', ' an', ' ancient', ',', ' mystical', ' artifact', ' rumored', ' to', ' hold', ' the', ' key', ' to', ' unlocking', ' the', ' secrets', ' of', ' the', ' universe', ',', ' while', ' his', ' loyal', ' assistant', ',', ' a', ' quick', '-', 'w', 'itted', ' and', ' resource', 'ful', ' graduate', ' student', ' with', ' a', ' penchant', ' for', ' solving', ' cryptic', ' puzzles', ',', ' followed', ' close', ' behind', ',', ' armed', ' only', ' with', ' a', ' we', 'athered', ' journal', ',', ' a', ' compass', ',', ' and', ' an', ' unw', 'avering', ' determination', ' to', ' unravel', ' the', ' mystery', ' that', ' had', ' haunted', ' her', ' mentor', ' for', ' decades', '.']\n",
      "\n",
      "Top prediction each prompt:\n",
      "['\\n', '\\n', '\\n', '\\n', ' But']\n"
     ]
    }
   ],
   "source": [
    "model.tokenizer.padding_side = \"left\"\n",
    "tokens = model.to_tokens(prompts)\n",
    "\n",
    "logits, cache = model.run_with_cache(tokens)\n",
    "print(logits.size())\n",
    "\n",
    "logits_final = logits[:, -1, :]\n",
    "print(logits_final.size())\n",
    "\n",
    "logits_sorted, logits_idx_sorted = logits_final.sort(\n",
    "    descending=True, stable=True, dim=-1\n",
    ")\n",
    "for prompt in prompts:\n",
    "    str_tokens = model.to_str_tokens(prompt)\n",
    "    print(\"Prompt length:\", len(str_tokens))\n",
    "    print(\"Prompt as tokens:\", str_tokens)\n",
    "print()\n",
    "print(f\"Top prediction each prompt:\\n{model.to_str_tokens(logits_idx_sorted[:, 1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top answers filtered by '\\<space\\>\\<titleword\\>' and corresponding incorrect answers\n",
    "\n",
    "- Could be missing something important here!\n",
    "\n",
    "- Implications for not taking very top? Hope it doesn't break later code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(' Go', ' go', 'Go', 'go'), (' I', ' i', 'I', 'i'), (' He', ' he', 'He', 'he'), (' This', ' this', 'This', 'this'), (' But', ' but', 'But', 'but')]\n",
      "tensor([[1514,  467, 5247, 2188],\n",
      "        [ 314, 1312,   40,   72],\n",
      "        [ 679,  339, 1544,  258],\n",
      "        [ 770,  428, 1212, 5661],\n",
      "        [ 887,  475, 1537, 4360]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "space_titleword_pattern = re.compile(\"\\s[A-Z]\\w*\")\n",
    "\n",
    "def titleword_answer_generator(logits_idx_sorted):\n",
    "    \"\"\"Generate a sequence of correct/incorrect answer tuples by sampling\n",
    "    the first '<space><titleword>' token in `logits_sorted_idx` and\n",
    "    finding the corresponding incorrect versions. I.e.,\n",
    "    '<titleword>' (no space), '<space><lowerword>', and '<lowerword>'\n",
    "    \"\"\"\n",
    "    answer_str_tokens = []\n",
    "    answer_tokens = []\n",
    "\n",
    "    for logits_sorted_for_prompt in logits_idx_sorted:\n",
    "\n",
    "        predictions_sorted = model.to_str_tokens(logits_sorted_for_prompt)\n",
    "        top_space_titleword_prediction = next(\n",
    "            pred\n",
    "            for pred in predictions_sorted[:100]\n",
    "            if space_titleword_pattern.match(pred)\n",
    "        )\n",
    "        top_space_titleword_token = model.to_single_token(\n",
    "            top_space_titleword_prediction\n",
    "        )\n",
    "\n",
    "        lowercase_counterpart_str_token = top_space_titleword_prediction.lower()\n",
    "        lowercase_counterpart_token = model.to_single_token(\n",
    "            lowercase_counterpart_str_token\n",
    "        )\n",
    "\n",
    "        nospace_counterpart_str_token = top_space_titleword_prediction.lstrip()\n",
    "        nospace_counterpart_token = model.to_single_token(nospace_counterpart_str_token)\n",
    "\n",
    "        nospace_lowercase_counterpart_str_token = (\n",
    "            lowercase_counterpart_str_token.lstrip()\n",
    "        )\n",
    "        nospace_lowercase_counterpart_token = model.to_single_token(\n",
    "            nospace_lowercase_counterpart_str_token\n",
    "        )\n",
    "\n",
    "        answer_str_tokens.append(\n",
    "            (\n",
    "                top_space_titleword_prediction,\n",
    "                lowercase_counterpart_str_token,\n",
    "                nospace_counterpart_str_token,\n",
    "                nospace_lowercase_counterpart_str_token,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        answer_tokens.append(\n",
    "            (\n",
    "                top_space_titleword_token,\n",
    "                lowercase_counterpart_token,\n",
    "                nospace_counterpart_token,\n",
    "                nospace_lowercase_counterpart_token,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    answer_tokens = torch.tensor(answer_tokens).to(device)\n",
    "\n",
    "    return answer_tokens, answer_str_tokens\n",
    "\n",
    "\n",
    "answer_tokens, answer_str_tokens = titleword_answer_generator(logits_idx_sorted)\n",
    "print(answer_str_tokens)\n",
    "print(answer_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate logit diffs for each of the three incorrect answer types\n",
    "- Please forgive the weird formatting in the `logits_to_ave_logit_diff()` cell! I like to use the `black` formatter, but it's being annoyingly bugger for that particualr cell! I don't understand why and am mindful of the timesink that troubleshooting it likely presents..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_ave_logit_diff_2(\n",
    "    logits, answer_tokens, per_prompt=False, print_=True, incorrect_idx=1\n",
    "):\n",
    "    \"\"\"A modified version of `logits_to_ave_logit_diff_2()` from the Exploratory Analysis\n",
    "    Demo that permits multiple incorrect answers in `answer_tokens` where the user\n",
    "    can specify an incorrect answer index for which to calculate the logit diff.\n",
    "    \"\"\"\n",
    "    final_logits = logits[:, -1, :]\n",
    "\n",
    "    answer_logits = final_logits.gather(\n",
    "        dim=-1, index=answer_tokens[:, [0, incorrect_idx]]\n",
    "    )\n",
    "    answer_logit_diff = answer_logits[:, 0] - answer_logits[:, 1]\n",
    "    answer_logit_diff_mean = answer_logit_diff.mean()\n",
    "\n",
    "    if print_:\n",
    "        print(\n",
    "            \"Per prompt logit difference:\",\n",
    "            answer_logit_diff.detach().cpu().round(decimals=3),\n",
    "        )\n",
    "        print(\n",
    "            \"Average logit difference:\",\n",
    "            round(answer_logit_diff_mean.item(), 3),\n",
    "        )\n",
    "\n",
    "    if per_prompt:\n",
    "        return answer_logit_diff\n",
    "    else:\n",
    "        return answer_logit_diff_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompts:\n",
      "'Go.'\n",
      "'Hello.'\n",
      "'Matthew doesn't know what he is doing.'\n",
      "'This is a sentence. This is another sentence.'\n",
      "'The enigmatic, silver-haired professor, known for his eccentric lectures on quantum entanglement and the nature of reality, embarked on a perilous journey through the mist-shrouded mountains of Bhutan, seeking an ancient, mystical artifact rumored to hold the key to unlocking the secrets of the universe, while his loyal assistant, a quick-witted and resourceful graduate student with a penchant for solving cryptic puzzles, followed close behind, armed only with a weathered journal, a compass, and an unwavering determination to unravel the mystery that had haunted her mentor for decades.'\n",
      "\n",
      "Top prediction per prompt:\n",
      "[' Go', ' I', ' He', ' This', ' But']\n",
      "\n",
      "Logit diffs for incorrect answer type: 'lowercase':\n",
      "Per prompt logit difference: tensor([5.0080, 5.9630, 7.7480, 6.4700, 7.8960])\n",
      "Average logit difference: 6.617\n",
      "\n",
      "Logit diffs for incorrect answer type: 'missing space':\n",
      "Per prompt logit difference: tensor([1.7910, 2.8110, 7.5470, 5.2680, 3.9150])\n",
      "Average logit difference: 4.266\n",
      "\n",
      "Logit diffs for incorrect answer type: 'lowercase and missing space':\n",
      "Per prompt logit difference: tensor([ 2.0660,  7.3190, 11.3110, 10.6940,  9.5120])\n",
      "Average logit difference: 8.181\n"
     ]
    }
   ],
   "source": [
    "idx_to_incorrect_answer_label = dict(\n",
    "    (\n",
    "        (1, \"lowercase\"),\n",
    "        (2, \"missing space\"),\n",
    "        (3, \"lowercase and missing space\"),\n",
    "    )\n",
    ")\n",
    "print(\"Prompts:\")\n",
    "for prompt in prompts:\n",
    "    print(f\"'{prompt}'\")\n",
    "\n",
    "print(f\"\\nTop prediction per prompt:\\n{[row[0] for row in answer_str_tokens]}\")\n",
    "for incorrect_idx in range(1, answer_tokens.size(1)):\n",
    "    print(\n",
    "        f\"\\nLogit diffs for incorrect answer type: '{idx_to_incorrect_answer_label[incorrect_idx]}':\"\n",
    "    )\n",
    "    logit_diffs = logits_to_ave_logit_diff_2(\n",
    "        logits, answer_tokens, per_prompt=True, incorrect_idx=incorrect_idx\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "\n",
    "- Average logit differences are high, with the min average implying $e^{4.266} \\approx 71 \\times$ more likely for the correct answer to be chosen then its incorrect counterpart\n",
    "\n",
    "- Missing space logit diff performs worst. Perhaps some of the training data included full-stop-separated words, like URLs?\n",
    "  - Although curiously missing space AND lowercase is least likely\n",
    "    - `\"go\"` following `\"Go.\"` is an outlier here\n",
    "  - Something is forcing the titlecasing?\n",
    "\n",
    "- Still very low data: cautious with above results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Logit Lens\n",
    "\n",
    "- Start with one incorrect case: lowercase version of same token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer residual directions shape: torch.Size([5, 2, 768])\n",
      "Logit difference directions shape: torch.Size([5, 768])\n"
     ]
    }
   ],
   "source": [
    "incorrect_idx = 1\n",
    "\n",
    "original_average_logit_diff = logits_to_ave_logit_diff_2(\n",
    "        logits, answer_tokens, per_prompt=False, incorrect_idx=incorrect_idx, print_=False)\n",
    "\n",
    "answer_residual_directions = model.tokens_to_residual_directions(answer_tokens[:, [0, incorrect_idx]])\n",
    "print(\"Answer residual directions shape:\", answer_residual_directions.shape)\n",
    "logit_diff_directions = (\n",
    "    answer_residual_directions[:, 0] - answer_residual_directions[:, 1]\n",
    ")\n",
    "print(\"Logit difference directions shape:\", logit_diff_directions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify okay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final residual stream shape: torch.Size([5, 116, 768])\n",
      "Calculated average logit diff: 7.233\n",
      "Original logit difference: 6.617\n"
     ]
    }
   ],
   "source": [
    "# cache syntax - resid_post is the residual stream at the end of the layer, -1 gets the final layer. The general syntax is [activation_name, layer_index, sub_layer_type].\n",
    "final_residual_stream = cache[\"resid_post\", -1]\n",
    "print(\"Final residual stream shape:\", final_residual_stream.shape)\n",
    "\n",
    "final_token_residual_stream = final_residual_stream[:, -1, :]\n",
    "# Apply LayerNorm scaling\n",
    "# pos_slice is the subset of the positions we take - here the final token of each prompt\n",
    "scaled_final_token_residual_stream = cache.apply_ln_to_stack(\n",
    "    final_token_residual_stream, layer=-1, pos_slice=-1\n",
    ")\n",
    "\n",
    "average_logit_diff = einsum(\n",
    "    \"batch d_model, batch d_model -> \",\n",
    "    scaled_final_token_residual_stream,\n",
    "    logit_diff_directions,\n",
    ") / len(prompts)\n",
    "print(\"Calculated average logit diff:\", round(average_logit_diff.item(), 3))\n",
    "print(\"Original logit difference:\", round(original_average_logit_diff.item(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **I don't understand the difference above. Let's simplify:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redefine `answers` and simpler `logit_to_ave_logit_diff()`. Stick to difference from lowercase version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1514,  467],\n",
      "        [ 314, 1312],\n",
      "        [ 679,  339],\n",
      "        [ 770,  428],\n",
      "        [ 887,  475]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "answers = [\n",
    "    (\" Go\", \" go\"),\n",
    "    (\" I\", \" i\"),\n",
    "    (\" He\", \" he\"),\n",
    "    (\" This\", \" this\"),\n",
    "    (\" But\", \" but\"),\n",
    "]\n",
    "\n",
    "answer_tokens = torch.tensor(\n",
    "    [[model.to_single_token(ans_row[0]), model.to_single_token(ans_row[1])] for ans_row in answers]\n",
    ").to(device)\n",
    "print(answer_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_ave_logit_diff(logits, answer_tokens, per_prompt=False):\n",
    "    # Only the final logits are relevant for the answer\n",
    "    final_logits = logits[:, -1, :]\n",
    "    answer_logits = final_logits.gather(dim=-1, index=answer_tokens)\n",
    "    answer_logit_diff = answer_logits[:, 0] - answer_logits[:, 1]\n",
    "    if per_prompt:\n",
    "        return answer_logit_diff\n",
    "    else:\n",
    "        return answer_logit_diff.mean()\n",
    "\n",
    "original_average_logit_diff = logits_to_ave_logit_diff(logits, answer_tokens, per_prompt=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that matches above..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Logit lens again\n",
    "\n",
    "- Code copied from [Exploratory Analysis Demo](https://colab.research.google.com/github/neelnanda-io/TransformerLens/blob/main/demos/Exploratory_Analysis_Demo.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer residual directions shape: torch.Size([5, 2, 768])\n",
      "Logit difference directions shape: torch.Size([5, 768])\n",
      "Final residual stream shape: torch.Size([5, 116, 768])\n",
      "Calculated average logit diff: 7.233\n",
      "Original logit difference: 6.617\n"
     ]
    }
   ],
   "source": [
    "answer_residual_directions = model.tokens_to_residual_directions(answer_tokens)\n",
    "print(\"Answer residual directions shape:\", answer_residual_directions.shape)\n",
    "logit_diff_directions = (\n",
    "    answer_residual_directions[:, 0] - answer_residual_directions[:, 1]\n",
    ")\n",
    "print(\"Logit difference directions shape:\", logit_diff_directions.shape)\n",
    "\n",
    "# cache syntax - resid_post is the residual stream at the end of the layer, -1 gets the final layer. The general syntax is [activation_name, layer_index, sub_layer_type].\n",
    "final_residual_stream = cache[\"resid_post\", -1]\n",
    "print(\"Final residual stream shape:\", final_residual_stream.shape)\n",
    "final_token_residual_stream = final_residual_stream[:, -1, :]\n",
    "# Apply LayerNorm scaling\n",
    "# pos_slice is the subset of the positions we take - here the final token of each prompt\n",
    "scaled_final_token_residual_stream = cache.apply_ln_to_stack(\n",
    "    final_token_residual_stream, layer=-1, pos_slice=-1\n",
    ")\n",
    "\n",
    "average_logit_diff = einsum(\n",
    "    \"batch d_model, batch d_model -> \",\n",
    "    scaled_final_token_residual_stream,\n",
    "    logit_diff_directions,\n",
    ") / len(prompts)\n",
    "print(\"Calculated average logit diff:\", round(average_logit_diff.item(), 3))\n",
    "print(\"Original logit difference:\", round(original_average_logit_diff.item(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Still different! (Exactly the same numbers)\n",
    "\n",
    "- Though it at least appears that the the new logic in `logits_to_ave_logit_diff_2()` and the handling of more incorrect answers in `answer_tokens` is not the cause"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try prompts of same length\n",
    "\n",
    "- Exploratory analysis demo warned about prompts of varying length\n",
    "\n",
    "- Perhaps the left padding flag is not enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt length: 11\n",
      "Prompt as tokens: ['<|endoftext|>', 'F', 'illing', ' up', ' to', ' eleven', ' tokens', '.', '\\n', 'Go', '.']\n",
      "Prompt length: 11\n",
      "Prompt as tokens: ['<|endoftext|>', 'Hello', '.', ' Hello', '.', ' Hello', '.', ' Hello', '.', ' Hello', '.']\n",
      "Prompt length: 11\n",
      "Prompt as tokens: ['<|endoftext|>', 'Yeah', ' Matt', ' doesn', \"'t\", ' know', ' what', ' he', ' is', ' doing', '.']\n",
      "Prompt length: 11\n",
      "Prompt as tokens: ['<|endoftext|>', 'That', ' Will', ' does', ' not', ' know', ' where', ' he', ' is', ' going', '.']\n",
      "Prompt length: 11\n",
      "Prompt as tokens: ['<|endoftext|>', 'Someone', ' should', ' really', ' help', ' them', ' out', ',', ' I', ' think', '.']\n",
      "Prompt length: 11\n",
      "Prompt as tokens: ['<|endoftext|>', 'It', ' is', ' wonderful', ' to', ' be', ' in', ' Adelaide', ' in', ' March', '.']\n",
      "Prompt length: 11\n",
      "Prompt as tokens: ['<|endoftext|>', 'Ko', 'al', 'as', ' are', ' cute', ',', ' but', ' gr', 'umpy', '.']\n",
      "Prompt length: 11\n",
      "Prompt as tokens: ['<|endoftext|>', 'This', ' is', ' a', ' sentence', '.', ' This', ' is', ' another', ' sentence', '.']\n",
      "Prompt length: 11\n",
      "Prompt as tokens: ['<|endoftext|>', 'F', 'illing', ' up', ' to', ' eleven', ' tokens', '.', '\\n', 'Go', '.']\n",
      "Prompt length: 11\n",
      "Prompt as tokens: ['<|endoftext|>', 'Hello', '.', ' Hello', '.', ' Hello', '.', ' Hello', '.', ' Hello', '.']\n",
      "Prompt length: 11\n",
      "Prompt as tokens: ['<|endoftext|>', 'Yeah', ' Matt', ' doesn', \"'t\", ' know', ' what', ' he', ' is', ' doing', '.']\n",
      "Prompt length: 11\n",
      "Prompt as tokens: ['<|endoftext|>', 'That', ' Will', ' does', ' not', ' know', ' where', ' he', ' is', ' going', '.']\n",
      "Prompt length: 11\n",
      "Prompt as tokens: ['<|endoftext|>', 'Someone', ' should', ' really', ' help', ' them', ' out', ',', ' I', ' think', '.']\n",
      "Prompt length: 11\n",
      "Prompt as tokens: ['<|endoftext|>', 'It', ' is', ' wonderful', ' to', ' be', ' in', ' Adelaide', ' in', ' March', '.']\n",
      "Prompt length: 11\n",
      "Prompt as tokens: ['<|endoftext|>', 'Ko', 'al', 'as', ' are', ' cute', ',', ' but', ' gr', 'umpy', '.']\n",
      "Prompt length: 11\n",
      "Prompt as tokens: ['<|endoftext|>', 'This', ' is', ' a', ' sentence', '.', ' This', ' is', ' another', ' sentence', '.']\n",
      "\n",
      "Top prediction each prompt:\n",
      "[' Go', '\\n', '\\n', ' He', ' I', ' It', '\\n', '\\n']\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Filling up to eleven tokens.\\nGo.\", # Single word sentence\n",
    "    \"Hello. Hello. Hello. Hello. Hello.\", # Repeat single word sentence\n",
    "    \"Yeah Matt doesn't know what he is doing.\", # More or less standard sentence\n",
    "    \"That Will does not know where he is going.\", # Different end verb\n",
    "    \"Someone should really help them out, I think.\", # Verb not ending in \"ing\", has comma\n",
    "    \"It is wonderful to be in Adelaide in March.\", # End noun, has comma\n",
    "    \"Koalas are cute, but grumpy.\", # End adjective\n",
    "    \"This is a sentence. This is another sentence.\", # Two sentences\n",
    "]\n",
    "for prompt in prompts:\n",
    "    str_tokens = model.to_str_tokens(prompt)\n",
    "    print(\"Prompt length:\", len(str_tokens))\n",
    "    print(\"Prompt as tokens:\", str_tokens)\n",
    "\n",
    "tokens = model.to_tokens(prompts)\n",
    "\n",
    "logits, cache = model.run_with_cache(tokens)\n",
    "logits_final = logits[:, -1, :]\n",
    "logits_sorted, logits_idx_sorted = logits_final.sort(\n",
    "    descending=True, stable=True, dim=-1\n",
    ")\n",
    "for prompt in prompts:\n",
    "    str_tokens = model.to_str_tokens(prompt)\n",
    "    print(\"Prompt length:\", len(str_tokens))\n",
    "    print(\"Prompt as tokens:\", str_tokens)\n",
    "print()\n",
    "print(f\"Top prediction each prompt:\\n{model.to_str_tokens(logits_idx_sorted[:, 1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate new answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(' Go', ' go', 'Go', 'go'),\n",
      " (' Hello', ' hello', 'Hello', 'hello'),\n",
      " (' He', ' he', 'He', 'he'),\n",
      " (' He', ' he', 'He', 'he'),\n",
      " (' I', ' i', 'I', 'i'),\n",
      " (' It', ' it', 'It', 'it'),\n",
      " (' They', ' they', 'They', 'they'),\n",
      " (' This', ' this', 'This', 'this')]\n",
      "tensor([[ 1514,   467,  5247,  2188],\n",
      "        [18435, 23748, 15496, 31373],\n",
      "        [  679,   339,  1544,   258],\n",
      "        [  679,   339,  1544,   258],\n",
      "        [  314,  1312,    40,    72],\n",
      "        [  632,   340,  1026,   270],\n",
      "        [ 1119,   484,  2990,  9930],\n",
      "        [  770,   428,  1212,  5661]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' Go', '\\n', '\\n', ' He', ' I', ' It', '\\n', '\\n']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "answer_tokens, answer_str_tokens = titleword_answer_generator(logits_idx_sorted)\n",
    "pprint(answer_str_tokens)\n",
    "print(answer_tokens)\n",
    "\n",
    "[' Go', '\\n', '\\n', ' He', ' I', ' It', '\\n', '\\n']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New logit diffs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompts:\n",
      "'Filling up to eleven tokens.\n",
      "Go.'\n",
      "'Hello. Hello. Hello. Hello. Hello.'\n",
      "'Yeah Matt doesn't know what he is doing.'\n",
      "'That Will does not know where he is going.'\n",
      "'Someone should really help them out, I think.'\n",
      "'It is wonderful to be in Adelaide in March.'\n",
      "'Koalas are cute, but grumpy.'\n",
      "'This is a sentence. This is another sentence.'\n",
      "\n",
      "Top space-titleword prediction per prompt:\n",
      "[' Go', ' Hello', ' He', ' He', ' I', ' It', ' They', ' This']\n",
      "\n",
      "Logit diffs for incorrect answer type: 'lowercase':\n",
      "Per prompt logit difference: tensor([5.5300, 5.4780, 5.8090, 6.1450, 6.2310, 7.7480, 8.2100, 6.4700])\n",
      "Average logit difference: 6.453\n",
      "\n",
      "Logit diffs for incorrect answer type: 'missing space':\n",
      "Per prompt logit difference: tensor([3.0500, 4.3010, 5.8150, 5.5950, 3.9660, 6.5970, 6.3920, 5.2680])\n",
      "Average logit difference: 5.123\n",
      "\n",
      "Logit diffs for incorrect answer type: 'lowercase and missing space':\n",
      "Per prompt logit difference: tensor([ 3.9800,  8.0950,  9.1950,  9.6280, 10.1990, 11.4920, 11.1240, 10.6940])\n",
      "Average logit difference: 9.301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Logit diffs for incorrect answer type: 'lowercase':\\nPer prompt logit difference: tensor([5.5300, 5.4780, 5.8090, 6.1450, 6.2310, 7.7480, 8.2100, 6.4700])\\nAverage logit difference: 6.453\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_incorrect_answer_label = dict(\n",
    "    (\n",
    "        (1, \"lowercase\"),\n",
    "        (2, \"missing space\"),\n",
    "        (3, \"lowercase and missing space\"),\n",
    "    )\n",
    ")\n",
    "print(\"Prompts:\")\n",
    "for prompt in prompts:\n",
    "    print(f\"'{prompt}'\")\n",
    "\n",
    "print(f\"\\nTop space-titleword prediction per prompt:\\n{[row[0] for row in answer_str_tokens]}\")\n",
    "for incorrect_idx in range(1, answer_tokens.size(1)):\n",
    "    print(\n",
    "        f\"\\nLogit diffs for incorrect answer type: '{idx_to_incorrect_answer_label[incorrect_idx]}':\"\n",
    "    )\n",
    "    logit_diffs = logits_to_ave_logit_diff_2(\n",
    "        logits, answer_tokens, per_prompt=True, incorrect_idx=incorrect_idx\n",
    "    )\n",
    "\n",
    "\"\"\"Logit diffs for incorrect answer type: 'lowercase':\n",
    "Per prompt logit difference: tensor([5.5300, 5.4780, 5.8090, 6.1450, 6.2310, 7.7480, 8.2100, 6.4700])\n",
    "Average logit difference: 6.453\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "- All values high now. Avoid sentences that are expected not to conform to standard English prose?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logit Lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_idx = 1\n",
    "\n",
    "original_average_logit_diff = logits_to_ave_logit_diff_2(logits, answer_tokens, per_prompt=False, incorrect_idx=incorrect_idx, print_=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer residual directions shape: torch.Size([8, 4, 768])\n",
      "Logit difference directions shape: torch.Size([8, 768])\n",
      "Final residual stream shape: torch.Size([8, 11, 768])\n",
      "Calculated average logit diff: 7.14\n",
      "Original logit difference: 6.453\n"
     ]
    }
   ],
   "source": [
    "answer_residual_directions = model.tokens_to_residual_directions(answer_tokens)\n",
    "print(\"Answer residual directions shape:\", answer_residual_directions.shape)\n",
    "\n",
    "logit_diff_directions = (\n",
    "    answer_residual_directions[:, 0] - answer_residual_directions[:, incorrect_idx]\n",
    ")\n",
    "print(\"Logit difference directions shape:\", logit_diff_directions.shape)\n",
    "\n",
    "# cache syntax - resid_post is the residual stream at the end of the layer, -1 gets the final layer. The general syntax is [activation_name, layer_index, sub_layer_type].\n",
    "final_residual_stream = cache[\"resid_post\", -1]\n",
    "print(\"Final residual stream shape:\", final_residual_stream.shape)\n",
    "final_token_residual_stream = final_residual_stream[:, -1, :]\n",
    "# Apply LayerNorm scaling\n",
    "# pos_slice is the subset of the positions we take - here the final token of each prompt\n",
    "scaled_final_token_residual_stream = cache.apply_ln_to_stack(\n",
    "    final_token_residual_stream, layer=-1, pos_slice=-1\n",
    ")\n",
    "\n",
    "average_logit_diff = einsum(\n",
    "    \"batch d_model, batch d_model -> \",\n",
    "    scaled_final_token_residual_stream,\n",
    "    logit_diff_directions,\n",
    ") / len(prompts)\n",
    "print(\"Calculated average logit diff:\", round(average_logit_diff.item(), 3))\n",
    "print(\"Original logit difference:\", round(original_average_logit_diff.item(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still different.\n",
    "- I think a possible cause is that I have not not been picking the top answer for each prompt\n",
    "as the correct answer.\n",
    "\n",
    "  - E.g., there may be some difference in scaling across the prompts that makes comparing\n",
    "an average invalid. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1514,  467],\n",
      "        [ 198, 1312],\n",
      "        [ 198, 1312],\n",
      "        [ 198, 1312],\n",
      "        [ 314, 1312],\n",
      "        [ 632,  340],\n",
      "        [ 198, 1312],\n",
      "        [ 198, 1312]], device='cuda:0')\n",
      "Answer residual directions shape: torch.Size([8, 2, 768])\n",
      "Logit difference directions shape: torch.Size([8, 768])\n",
      "Final residual stream shape: torch.Size([8, 2, 768])\n",
      "Calculated average logit diff: -1.614\n",
      "Original logit difference: 0.233\n"
     ]
    }
   ],
   "source": [
    "top_answers = [\n",
    "    (\" Go\", \" go\"),\n",
    "    (\"\\n\", \" i\"),\n",
    "    (\"\\n\", \" i\"),\n",
    "    (\"\\n\", \" i\"),\n",
    "    (\" I\", \" i\"),\n",
    "    (\" It\", \" it\"),\n",
    "    (\"\\n\", \" i\"),\n",
    "    (\"\\n\", \" i\"),\n",
    "]\n",
    "\n",
    "top_answer_tokens = torch.tensor(\n",
    "    [[model.to_single_token(ans_row[0]), model.to_single_token(ans_row[1])] for ans_row in top_answers]\n",
    ").to(device)\n",
    "print(top_answer_tokens)\n",
    "logits_top_answer, cache_top_answer = model.run_with_cache(top_answer_tokens)\n",
    "original_average_logit_diff = logits_to_ave_logit_diff_2(logits_top_answer, top_answer_tokens, per_prompt=False, incorrect_idx=1, print_=False)\n",
    "\n",
    "answer_residual_directions = model.tokens_to_residual_directions(top_answer_tokens)\n",
    "print(\"Answer residual directions shape:\", answer_residual_directions.shape)\n",
    "\n",
    "top_answer_logit_diff_directions = (\n",
    "    answer_residual_directions[:, 0] - answer_residual_directions[:, 1]\n",
    ")\n",
    "print(\"Logit difference directions shape:\", top_answer_logit_diff_directions.shape)\n",
    "\n",
    "# cache syntax - resid_post is the residual stream at the end of the layer, -1 gets the final layer. The general syntax is [activation_name, layer_index, sub_layer_type].\n",
    "final_residual_stream = cache_top_answer[\"resid_post\", -1]\n",
    "print(\"Final residual stream shape:\", final_residual_stream.shape)\n",
    "final_token_residual_stream = final_residual_stream[:, -1, :]\n",
    "# Apply LayerNorm scaling\n",
    "# pos_slice is the subset of the positions we take - here the final token of each prompt\n",
    "scaled_final_token_residual_stream = cache_top_answer.apply_ln_to_stack(\n",
    "    final_token_residual_stream, layer=-1, pos_slice=-1\n",
    ")\n",
    "\n",
    "average_logit_diff = einsum(\n",
    "    \"batch d_model, batch d_model -> \",\n",
    "    scaled_final_token_residual_stream,\n",
    "    top_answer_logit_diff_directions,\n",
    ") / len(top_answers)\n",
    "print(\"Calculated average logit diff:\", round(average_logit_diff.item(), 3))\n",
    "print(\"Original logit difference:\", round(original_average_logit_diff.item(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm. Still no good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the interest of time, press on\n",
    "\n",
    "- In normal circumstances, I would seek advice from a colleague/mentor on cause/importance of this difference in scaling.\n",
    "\n",
    "- I have a small hunch that the difference may not overly adversely impact meaningfulness of results.\n",
    "\n",
    "- Press on as if no difference for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_average_logit_diff = logits_to_ave_logit_diff_2(logits, answer_tokens, per_prompt=False, incorrect_idx=1, print_=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logit Lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_stack_to_logit_diff(\n",
    "    residual_stack: Float[torch.Tensor, \"components batch d_model\"],\n",
    "    cache: ActivationCache,\n",
    ") -> float:\n",
    "    scaled_residual_stack = cache.apply_ln_to_stack(\n",
    "        residual_stack, layer=-1, pos_slice=-1\n",
    "    )\n",
    "    return einsum(\n",
    "        \"... batch d_model, batch d_model -> ...\",\n",
    "        scaled_residual_stack,\n",
    "        logit_diff_directions,\n",
    "    ) / len(prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>x=%{x}<br>y=%{y}<extra></extra>",
         "hovertext": [
          "0_pre",
          "0_mid",
          "1_pre",
          "1_mid",
          "2_pre",
          "2_mid",
          "3_pre",
          "3_mid",
          "4_pre",
          "4_mid",
          "5_pre",
          "5_mid",
          "6_pre",
          "6_mid",
          "7_pre",
          "7_mid",
          "8_pre",
          "8_mid",
          "9_pre",
          "9_mid",
          "10_pre",
          "10_mid",
          "11_pre",
          "11_mid",
          "final_post"
         ],
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          0.5,
          1,
          1.5,
          2,
          2.5,
          3,
          3.5,
          4,
          4.5,
          5,
          5.5,
          6,
          6.5,
          7,
          7.5,
          8,
          8.5,
          9,
          9.5,
          10,
          10.5,
          11,
          11.5,
          12
         ],
         "xaxis": "x",
         "y": [
          0.006045743823051453,
          0.3832247257232666,
          0.8227099776268005,
          0.8222269415855408,
          0.9625974297523499,
          0.966791033744812,
          1.0316193103790283,
          1.0313239097595215,
          1.162224292755127,
          1.1547267436981201,
          1.2580480575561523,
          1.3580373525619507,
          1.4630929231643677,
          1.4921249151229858,
          1.794796347618103,
          1.8556709289550781,
          2.268353223800659,
          2.3155112266540527,
          2.9885880947113037,
          3.1024842262268066,
          3.922022581100464,
          4.0002827644348145,
          4.986746311187744,
          5.366740703582764,
          7.1402506828308105
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Logit Difference From Accumulated Residual Stream"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accumulated_residual, labels = cache.accumulated_resid(\n",
    "    layer=-1, incl_mid=True, pos_slice=-1, return_labels=True\n",
    ")\n",
    "logit_lens_logit_diffs = residual_stack_to_logit_diff(accumulated_residual, cache)\n",
    "line(\n",
    "    logit_lens_logit_diffs,\n",
    "    x=np.arange(model.cfg.n_layers * 2 + 1) / 2,\n",
    "    hover_name=labels,\n",
    "    title=\"Logit Difference From Accumulated Residual Stream\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "<b>%{hovertext}</b><br><br>x=%{x}<br>y=%{y}<extra></extra>",
         "hovertext": [
          "embed",
          "pos_embed",
          "0_attn_out",
          "0_mlp_out",
          "1_attn_out",
          "1_mlp_out",
          "2_attn_out",
          "2_mlp_out",
          "3_attn_out",
          "3_mlp_out",
          "4_attn_out",
          "4_mlp_out",
          "5_attn_out",
          "5_mlp_out",
          "6_attn_out",
          "6_mlp_out",
          "7_attn_out",
          "7_mlp_out",
          "8_attn_out",
          "8_mlp_out",
          "9_attn_out",
          "9_mlp_out",
          "10_attn_out",
          "10_mlp_out",
          "11_attn_out",
          "11_mlp_out"
         ],
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25
         ],
         "xaxis": "x",
         "y": [
          0.004200339317321777,
          0.00184540543705225,
          0.37717893719673157,
          0.4394853711128235,
          -0.0004830812104046345,
          0.1403704583644867,
          0.004193556495010853,
          0.0648283064365387,
          -0.00029546557925641537,
          0.13090047240257263,
          -0.0074976044707000256,
          0.1033213809132576,
          0.09998930245637894,
          0.10505566745996475,
          0.029031962156295776,
          0.3026711344718933,
          0.06087451055645943,
          0.4126826226711273,
          0.047157786786556244,
          0.6730771064758301,
          0.11389625072479248,
          0.8195381760597229,
          0.07825981825590134,
          0.9864639043807983,
          0.37999430298805237,
          1.7735100984573364
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Logit Difference From Each Layer"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "per_layer_residual, labels = cache.decompose_resid(\n",
    "    layer=-1, pos_slice=-1, return_labels=True\n",
    ")\n",
    "per_layer_logit_diffs = residual_stack_to_logit_diff(per_layer_residual, cache)\n",
    "line(per_layer_logit_diffs, hover_name=labels, title=\"Logit Difference From Each Layer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "\n",
    "- It appears that MLP layers are primarily what matters.\n",
    "\n",
    "- Especially the later ones (with increasing effect toward the later layers)\n",
    "\n",
    "- With my limited understanding of transformers, this makes some sense. It seems to me that the most important information for predicting a space-titleword token next is the nature of the *current* position/token: it is a \"sentence terminating character\". Since MLP layers are used to process information at a position, I think this info is likely \"determined/used\" in MLP layera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Head Attribution\n",
    "\n",
    "- Just out of interest, of course heads are parts of attention layers, which are apparently relatively unimportant - at least directly - according to the layer attribution graph above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tried to stack head results when they weren't cached. Computing head results now\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Head: %{x}<br>Layer: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "xaxis": "x",
         "yaxis": "y",
         "z": [
          [
           -0.0014938986860215664,
           0.13968972861766815,
           0.051865458488464355,
           -0.021638432517647743,
           0.03641578555107117,
           -0.011396054178476334,
           0.003805173560976982,
           -0.0052239010110497475,
           0.0640220195055008,
           0.07961846888065338,
           -0.011879147961735725,
           0.07643289119005203
          ],
          [
           0.003184700384736061,
           0.01621519774198532,
           -0.009807128459215164,
           -0.05302409827709198,
           -0.0066294483840465546,
           -0.01596742682158947,
           0.02402934432029724,
           -0.029515597969293594,
           0.024050267413258553,
           -0.00029715243726968765,
           0.04122340306639671,
           0.013555868528783321
          ],
          [
           0.016342859715223312,
           0.006091217510402203,
           0.007417414337396622,
           0.03459965065121651,
           0.005218225531280041,
           0.02120096981525421,
           -0.016758915036916733,
           -0.000031053321436047554,
           -0.040174681693315506,
           -0.005849276203662157,
           0.0331154391169548,
           -0.03754034638404846
          ],
          [
           -0.007055611349642277,
           0.011210334487259388,
           -0.010543654672801495,
           0.002857946092262864,
           0.0127693647518754,
           0.008187944069504738,
           0.007670317776501179,
           -0.013586434535682201,
           0.00955929048359394,
           -0.0178139079362154,
           -0.0055366745218634605,
           0.007116546388715506
          ],
          [
           -0.000022641383111476898,
           0.008579779416322708,
           0.013949668034911156,
           -0.002847732976078987,
           -0.007296031806617975,
           0.00047748791985213757,
           0.009718409739434719,
           -0.00861334428191185,
           -0.020505432039499283,
           0.0013998711947351694,
           -0.030341599136590958,
           -0.01299980003386736
          ],
          [
           0.027127321809530258,
           0.009810203686356544,
           -0.023552048951387405,
           0.028572235256433487,
           0.0023444960825145245,
           0.004866709001362324,
           -0.00030669476836919785,
           0.003629095619544387,
           0.015889111906290054,
           -0.0024542827159166336,
           0.013718429021537304,
           0.0027631442062556744
          ],
          [
           0.012586550787091255,
           -0.023649467155337334,
           -0.01778758317232132,
           0.03553362935781479,
           -0.006383370142430067,
           0.03994297981262207,
           -0.03589501604437828,
           0.0008054864592850208,
           -0.024975385516881943,
           0.07118445634841919,
           -0.02967708930373192,
           0.008445590734481812
          ],
          [
           -0.01522522047162056,
           0.023592522367835045,
           0.006095473654568195,
           0.0013961773365736008,
           0.0014202874153852463,
           0.007191944867372513,
           -0.029576608911156654,
           -0.007732166908681393,
           0.009334776550531387,
           0.007915428839623928,
           0.01366115640848875,
           0.00023310072720050812
          ],
          [
           -0.025818677619099617,
           -0.009494679048657417,
           0.03443802520632744,
           0.03828265890479088,
           0.010000464506447315,
           -0.027104929089546204,
           -0.003413938218727708,
           -0.011898251250386238,
           0.003025502897799015,
           0.010870951227843761,
           -0.019112039357423782,
           0.016133205965161324
          ],
          [
           0.020969213917851448,
           0.0029781078919768333,
           -0.011268899776041508,
           -0.031218767166137695,
           0.028546325862407684,
           -0.04408768564462662,
           0.05492280796170235,
           0.019870737567543983,
           -0.004012224730104208,
           0.029311448335647583,
           -0.010277105495333672,
           -0.01068611815571785
          ],
          [
           0.016249025240540504,
           0.04799671471118927,
           0.06201693043112755,
           -0.015740498900413513,
           -0.016057083383202553,
           0.017119163647294044,
           0.02099880576133728,
           -0.11150235682725906,
           -0.007382892072200775,
           -0.035176098346710205,
           0.04291561245918274,
           0.003111638128757477
          ],
          [
           0.3661387264728546,
           0.01851698011159897,
           0.010484859347343445,
           0.06106368079781532,
           -0.020444661378860474,
           0.015306377783417702,
           -0.002700790762901306,
           -0.04678390175104141,
           -0.04707641154527664,
           0.01908768340945244,
           -0.03684485703706741,
           0.018260616809129715
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "cmid": 0,
         "colorscale": [
          [
           0,
           "rgb(103,0,31)"
          ],
          [
           0.1,
           "rgb(178,24,43)"
          ],
          [
           0.2,
           "rgb(214,96,77)"
          ],
          [
           0.3,
           "rgb(244,165,130)"
          ],
          [
           0.4,
           "rgb(253,219,199)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(209,229,240)"
          ],
          [
           0.7,
           "rgb(146,197,222)"
          ],
          [
           0.8,
           "rgb(67,147,195)"
          ],
          [
           0.9,
           "rgb(33,102,172)"
          ],
          [
           1,
           "rgb(5,48,97)"
          ]
         ]
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Logit Difference From Each Head"
        },
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y",
         "title": {
          "text": "Head"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Layer"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "per_head_residual, labels = cache.stack_head_results(\n",
    "    layer=-1, pos_slice=-1, return_labels=True\n",
    ")\n",
    "per_head_logit_diffs = residual_stack_to_logit_diff(per_head_residual, cache)\n",
    "per_head_logit_diffs = einops.rearrange(\n",
    "    per_head_logit_diffs,\n",
    "    \"(layer head_index) -> layer head_index\",\n",
    "    layer=model.cfg.n_layers,\n",
    "    head_index=model.cfg.n_heads,\n",
    ")\n",
    "imshow(\n",
    "    per_head_logit_diffs,\n",
    "    labels={\"x\": \"Head\", \"y\": \"Layer\"},\n",
    "    title=\"Logit Difference From Each Head\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "- `0.1`, `10.7` and `11.0` look most interesting, in at least relative to the others.\n",
    "\n",
    "- Note the colormap  scale. Not much effect - at least as compared to IOI! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_attention_patterns(\n",
    "    heads: Union[List[int], int, Float[torch.Tensor, \"heads\"]],\n",
    "    local_cache: ActivationCache,\n",
    "    local_tokens: torch.Tensor,\n",
    "    title: Optional[str] = \"\",\n",
    "    max_width: Optional[int] = 700,\n",
    ") -> str:\n",
    "    # If a single head is given, convert to a list\n",
    "    if isinstance(heads, int):\n",
    "        heads = [heads]\n",
    "\n",
    "    # Create the plotting data\n",
    "    labels: List[str] = []\n",
    "    patterns: List[Float[torch.Tensor, \"dest_pos src_pos\"]] = []\n",
    "\n",
    "    # Assume we have a single batch item\n",
    "    batch_index = 0\n",
    "\n",
    "    for head in heads:\n",
    "        # Set the label\n",
    "        layer = head // model.cfg.n_heads\n",
    "        head_index = head % model.cfg.n_heads\n",
    "        labels.append(f\"L{layer}H{head_index}\")\n",
    "\n",
    "        # Get the attention patterns for the head\n",
    "        # Attention patterns have shape [batch, head_index, query_pos, key_pos]\n",
    "        patterns.append(local_cache[\"attn\", layer][batch_index, head_index])\n",
    "\n",
    "    # Convert the tokens to strings (for the axis labels)\n",
    "    str_tokens = model.to_str_tokens(local_tokens)\n",
    "\n",
    "    # Combine the patterns into a single tensor\n",
    "    patterns: Float[torch.Tensor, \"head_index dest_pos src_pos\"] = torch.stack(\n",
    "        patterns, dim=0\n",
    "    )\n",
    "\n",
    "    # Circuitsvis Plot (note we get the code version so we can concatenate with the title)\n",
    "    plot = attention_heads(\n",
    "        attention=patterns, tokens=str_tokens, attention_head_names=labels\n",
    "    ).show_code()\n",
    "\n",
    "    # Display the title\n",
    "    title_html = f\"<h2>{title}</h2><br/>\"\n",
    "\n",
    "    # Return the visualisation as raw code\n",
    "    return f\"<div style='max-width: {str(max_width)}px;'>{title_html + plot}</div>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='max-width: 700px;'><h2>Top 3 Positive Logit Attribution Heads</h2><br/><div id=\"circuits-vis-f6a175c0-afe5\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionHeads } from \"https://unpkg.com/circuitsvis@1.41.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-f6a175c0-afe5\",\n",
       "      AttentionHeads,\n",
       "      {\"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8072689771652222, 0.19273103773593903, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.39606568217277527, 0.34098777174949646, 0.2629465162754059, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3663756251335144, 0.21596617996692657, 0.16522450745105743, 0.2524336874485016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.41715314984321594, 0.07133759558200836, 0.1765328198671341, 0.18711544573307037, 0.14786097407341003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2636759877204895, 0.10417738556861877, 0.12840785086154938, 0.16137582063674927, 0.2307903915643692, 0.11157253384590149, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2513483762741089, 0.03102060966193676, 0.1118660718202591, 0.12479223310947418, 0.16409258544445038, 0.06572666019201279, 0.25115346908569336, 0.0, 0.0, 0.0, 0.0], [0.21268317103385925, 0.03146596997976303, 0.05042346194386482, 0.03470305725932121, 0.0344177782535553, 0.07105568796396255, 0.2012922316789627, 0.3639586567878723, 0.0, 0.0, 0.0], [0.4236028790473938, 0.08953793346881866, 0.03296317905187607, 0.059110891073942184, 0.04823220148682594, 0.029885629191994667, 0.06305036693811417, 0.20218731462955475, 0.05142956227064133, 0.0, 0.0], [0.38477569818496704, 0.030375583097338676, 0.0950409397482872, 0.06556392461061478, 0.06274737417697906, 0.044236667454242706, 0.10454637557268143, 0.052109021693468094, 0.04355261102318764, 0.11705182492733002, 0.0], [0.279458224773407, 0.02987462840974331, 0.038733407855033875, 0.029440609738230705, 0.018166588619351387, 0.05895372852683067, 0.11027822643518448, 0.14086852967739105, 0.10552056133747101, 0.08296068757772446, 0.10574482381343842]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0003789146721828729, 0.9996210336685181, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [7.339733565459028e-05, 0.00249064271338284, 0.997435986995697, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.000272715522442013, 0.0006405745516531169, 0.00042986171320080757, 0.9986567497253418, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0031309062615036964, 0.005285950377583504, 0.0005039328243583441, 0.0392005555331707, 0.9518786072731018, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.5006581634224858e-05, 6.465916521847248e-05, 7.871762500144541e-05, 0.000309374911012128, 1.9874385543516837e-05, 0.9995124340057373, 0.0, 0.0, 0.0, 0.0, 0.0], [2.8403410397004336e-05, 0.00016516898176632822, 0.00024424202274531126, 0.00022291061759460717, 0.0002609155490063131, 5.128303382662125e-05, 0.9990271329879761, 0.0, 0.0, 0.0, 0.0], [0.01459337119013071, 0.0007895631133578718, 0.0002272736164741218, 0.0016011694679036736, 0.008408202789723873, 0.00022517700563184917, 0.0001214134317706339, 0.974033772945404, 0.0, 0.0, 0.0], [0.12343044579029083, 0.002977535827085376, 0.00016131121083162725, 0.002607922535389662, 0.015600915998220444, 0.0005669486126862466, 0.00028066179947927594, 0.029705077409744263, 0.8246690630912781, 0.0, 0.0], [0.0004206265730317682, 0.0005183183820918202, 1.9357255951035768e-05, 0.002515322295948863, 0.0002679186291061342, 9.628591942600906e-05, 4.139124575885944e-05, 9.848583431448787e-05, 0.00015695048205088824, 0.9958653450012207, 0.0], [0.006992611102759838, 0.00026965048164129257, 9.33531773625873e-05, 0.0005566492327488959, 0.003398501081392169, 9.012317605083808e-05, 4.88293262606021e-05, 0.4936283528804779, 0.0007231304189190269, 0.00018264535174239427, 0.494016170501709]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8863518238067627, 0.11364816874265671, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8223246932029724, 0.12285574525594711, 0.05481952801346779, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6597962975502014, 0.13186155259609222, 0.09022696316242218, 0.11811515688896179, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5374982953071594, 0.10205129534006119, 0.07093988358974457, 0.11689736694097519, 0.17261311411857605, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5872894525527954, 0.0934605747461319, 0.06371767073869705, 0.09478840976953506, 0.1269172728061676, 0.033826541155576706, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5791822671890259, 0.07336998730897903, 0.07208143174648285, 0.0971742793917656, 0.1106189638376236, 0.06253305822610855, 0.005039966199547052, 0.0, 0.0, 0.0, 0.0], [0.41226157546043396, 0.08403193950653076, 0.06497921049594879, 0.08240451663732529, 0.1135256290435791, 0.08618047833442688, 0.051633309572935104, 0.10498332232236862, 0.0, 0.0, 0.0], [0.39365407824516296, 0.07591336965560913, 0.046394579112529755, 0.07028605043888092, 0.09299015253782272, 0.06505908071994781, 0.047869399189949036, 0.0902475044131279, 0.11758583039045334, 0.0, 0.0], [0.41130104660987854, 0.07555819302797318, 0.052536338567733765, 0.06240198016166687, 0.09075046330690384, 0.056925609707832336, 0.04081985354423523, 0.08629385381937027, 0.09569065272808075, 0.02772204950451851, 0.0], [0.3104654848575592, 0.06304948031902313, 0.049866124987602234, 0.06299315392971039, 0.08474995195865631, 0.06870544701814651, 0.043538715690374374, 0.08206064254045486, 0.09618567675352097, 0.052229367196559906, 0.086155965924263]]], \"attentionHeadNames\": [\"L11H0\", \"L0H1\", \"L0H9\"], \"tokens\": [\"<|endoftext|>\", \"F\", \"illing\", \" up\", \" to\", \" eleven\", \" tokens\", \".\", \"\\n\", \"Go\", \".\"], \"maskUpperTri\": true}\n",
       "    )\n",
       "    </script></div><div style='max-width: 700px;'><h2>Top 3 Negative Logit Attribution Heads</h2><br/><div id=\"circuits-vis-f4be9c2e-b104\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionHeads } from \"https://unpkg.com/circuitsvis@1.41.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-f4be9c2e-b104\",\n",
       "      AttentionHeads,\n",
       "      {\"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9896830320358276, 0.010316967964172363, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9097660779953003, 0.007996486499905586, 0.08223740756511688, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.911576509475708, 0.005346783436834812, 0.049682892858982086, 0.03339386731386185, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9024960398674011, 0.003855999791994691, 0.018018275499343872, 0.02796141617000103, 0.0476682223379612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.823502779006958, 0.008665203116834164, 0.020909957587718964, 0.02021244913339615, 0.0855812281370163, 0.04112840071320534, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8905805349349976, 0.0012030750513076782, 0.025259073823690414, 0.015033013187348843, 0.01411410141736269, 0.0067208451218903065, 0.04708944633603096, 0.0, 0.0, 0.0, 0.0], [0.6700867414474487, 0.021110989153385162, 0.04497728496789932, 0.013027379289269447, 0.029727431014180183, 0.01465862337499857, 0.11803118884563446, 0.08838041126728058, 0.0, 0.0, 0.0], [0.8667372465133667, 0.017448168247938156, 0.025347502902150154, 0.004399971570819616, 0.009580415673553944, 0.012228071689605713, 0.022956132888793945, 0.023709993809461594, 0.017592409625649452, 0.0, 0.0], [0.9223873019218445, 0.0013068616390228271, 0.005331001244485378, 0.016684364527463913, 0.01177915371954441, 0.0035071424208581448, 0.013923993334174156, 0.00856175646185875, 0.006855495274066925, 0.009662853553891182, 0.0], [0.5346782207489014, 0.007940990850329399, 0.007380958646535873, 0.013646593317389488, 0.019117776304483414, 0.0009748418815433979, 0.0066255684942007065, 0.024295520037412643, 0.01595330238342285, 0.3166271150112152, 0.05275912210345268]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6402127742767334, 0.3597872257232666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6083611249923706, 0.1554824858903885, 0.23615635931491852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5571038722991943, 0.11275038868188858, 0.1664961874485016, 0.16364963352680206, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5322960615158081, 0.08492660522460938, 0.1233275979757309, 0.1219213679432869, 0.1375284343957901, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5030842423439026, 0.06465210020542145, 0.09800052642822266, 0.10096723586320877, 0.10966020822525024, 0.1236356869339943, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5158265233039856, 0.05033392086625099, 0.07370569556951523, 0.07643386721611023, 0.08517623692750931, 0.0936669260263443, 0.10485684871673584, 0.0, 0.0, 0.0, 0.0], [0.4881276786327362, 0.041345324367284775, 0.06142343953251839, 0.06457295268774033, 0.06967658549547195, 0.07961196452379227, 0.09200466424226761, 0.10323739796876907, 0.0, 0.0, 0.0], [0.5157991051673889, 0.03431041166186333, 0.04698682203888893, 0.05065983906388283, 0.053846586495637894, 0.06162455305457115, 0.07109080255031586, 0.07982474565505981, 0.08585712313652039, 0.0, 0.0], [0.4730377197265625, 0.026124071329832077, 0.04217160865664482, 0.046211812645196915, 0.05105584114789963, 0.058182720094919205, 0.07158654183149338, 0.07934290915727615, 0.08633682131767273, 0.0659499242901802, 0.0], [0.493515282869339, 0.022209173068404198, 0.035175472497940063, 0.038810670375823975, 0.04241131991147995, 0.04732691869139671, 0.05801001191139221, 0.06369880586862564, 0.07061409950256348, 0.05646407604217529, 0.07176416367292404]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.6158908692887053e-05, 0.9999837875366211, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [7.447151438100263e-05, 0.2990161180496216, 0.7009094953536987, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0448620741954073e-05, 0.03809225559234619, 0.7453977465629578, 0.2164994776248932, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.822132566710934e-05, 0.07569266855716705, 0.3964516520500183, 0.2907618582248688, 0.23705556988716125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [6.234633474377915e-05, 0.024423930794000626, 0.31949862837791443, 0.249970480799675, 0.2933807373046875, 0.11266382783651352, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00017571081116329879, 0.01200109627097845, 0.14916783571243286, 0.16081871092319489, 0.11593758314847946, 0.10846617072820663, 0.4534328877925873, 0.0, 0.0, 0.0, 0.0], [3.92253277823329e-05, 0.01687263324856758, 0.023393522948026657, 0.029201894998550415, 0.04702307656407356, 0.029026314616203308, 0.41538330912590027, 0.4390599727630615, 0.0, 0.0, 0.0], [4.4625943701248616e-05, 0.06790554523468018, 0.0385015532374382, 0.021173741668462753, 0.06422211974859238, 0.043039560317993164, 0.4039727747440338, 0.094691202044487, 0.26644882559776306, 0.0, 0.0], [3.9511785871582106e-05, 0.08310185372829437, 0.06755661219358444, 0.06778270751237869, 0.12312672287225723, 0.0479118674993515, 0.12547047436237335, 0.13230925798416138, 0.20652955770492554, 0.1461714208126068, 0.0], [3.69819208572153e-05, 0.07067035883665085, 0.06136611849069595, 0.05778883770108223, 0.05082797259092331, 0.03761334717273712, 0.08099835366010666, 0.13220776617527008, 0.09830550104379654, 0.18730495870113373, 0.22287976741790771]]], \"attentionHeadNames\": [\"L10H7\", \"L1H3\", \"L11H8\"], \"tokens\": [\"<|endoftext|>\", \"F\", \"illing\", \" up\", \" to\", \" eleven\", \" tokens\", \".\", \"\\n\", \"Go\", \".\"], \"maskUpperTri\": true}\n",
       "    )\n",
       "    </script></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = 3\n",
    "\n",
    "top_positive_logit_attr_heads = torch.topk(\n",
    "    per_head_logit_diffs.flatten(), k=top_k\n",
    ").indices\n",
    "\n",
    "positive_html = visualize_attention_patterns(\n",
    "    top_positive_logit_attr_heads,\n",
    "    cache,\n",
    "    tokens[0],\n",
    "    f\"Top {top_k} Positive Logit Attribution Heads\",\n",
    ")\n",
    "\n",
    "top_negative_logit_attr_heads = torch.topk(\n",
    "    -per_head_logit_diffs.flatten(), k=top_k\n",
    ").indices\n",
    "\n",
    "negative_html = visualize_attention_patterns(\n",
    "    top_negative_logit_attr_heads,\n",
    "    cache,\n",
    "    tokens[0],\n",
    "    title=f\"Top {top_k} Negative Logit Attribution Heads\",\n",
    ")\n",
    "\n",
    "HTML(positive_html + negative_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations:\n",
    "\n",
    "- In the strongest head, `11.0`, token `1` attends strongly (relatively speaking) to token `0` (`<|endoftext|>`). This might contribute to capitalisation of token `1`?\n",
    "\n",
    "- In `0.1`, the final token (`\".\"`) attends fairly strongly to token `7`, which is another full stop in at least one of the prompts.\n",
    "\n",
    "- In `10.7`, attention to the second to last token negatively contributes to the logits of the final token.\n",
    "  - One (major?) flaw in this analysis is investigating only the first titleword token. For the selection of prompts I chose, perhaps the token immediately preceding the final full stop contributes to a stronger prediction of some other token (the newline?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Stream Patching\n",
    "\n",
    "- **Note**: It's difficult to for me to know how much wisdom I can draw from this section. The \"corrupted\" prompts below do significantly increase the logits for the \\<space\\>\\<**lowercase**\\> version of the next token, but they do not meaningfully *reduce* the logits of the \"clean\" token. It is not a neat reversal like the IOI example\n",
    "\n",
    "- The problem is: I'm struggling to think of a way to manufacture such a reversal, especially using the *relevant circuitry*. I'm sure I am missing something, but this seems like a difficult problem to provide an input that tests the \"capitalise next word after full stop\" circuit for which I can provide a corrupted input that produces an uncapitalised first word.\n",
    "  - E.g., perhaps I could exclusively use **repeat sequences** of a single word (e.g., clean version:`[\"Go. Go. Go. Go\"]`, corrupted version:`[\"go. go. go. go\"]`), but it seems likely that some *different circuit* (e.g., duplication) produces capitalised output in the clean case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3130542326.py, line 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[31], line 25\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"\"\"\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "prompts_corrupted = [\n",
    "    \"filling up to eleven tokens.\\ngo.\", \n",
    "    \"hello. hello. hello. hello. hello.\", \n",
    "    \"yeah Matt doesn't know what he is doing.\", \n",
    "    \"that Will does not know where he is going.\",\n",
    "    \"someone should really help them out, I think.\", \n",
    "    \"it is wonderful to be in Adelaide in March.\",\n",
    "    \"koalas are cute, but grumpy.\", \n",
    "    \"this is a sentence. this is another sentence.\",\n",
    "]\n",
    "\n",
    "tokens_corrupted = model.to_tokens(prompts_corrupted)\n",
    "\n",
    "logits_corrupted, cache_corrupted = model.run_with_cache(tokens_corrupted)\n",
    "logits_final_corrupted = logits_corrupted[:, -1, :]\n",
    "logits_sorted_corrupted, logits_idx_sorted_corrupted = logits_final_corrupted.sort(\n",
    "    descending=True, stable=True, dim=-1\n",
    ")\n",
    "average_logit_diff_corrupted = logits_to_ave_logit_diff_2(logits_corrupted, answer_tokens, per_prompt=False, incorrect_idx=1, print_=True)\n",
    "print(\"\\nCorrupted Average Logit Diff\", round(average_logit_diff_corrupted.item(), 2))\n",
    "print(\"Clean Average Logit Diff\", round(original_average_logit_diff.item(), 2))\n",
    "utils.test_prompt(prompts_corrupted[1], answer_str_tokens[1][0], model, top_k=1)\n",
    "utils.test_prompt(prompts_corrupted[1], answer_str_tokens[1][1], model, top_k=1)\n",
    "\n",
    "    \"\"\"\n",
    "Per prompt logit difference: tensor([ 1.3570, -2.6480, -1.0820,  3.3580,  2.7450,  2.0550,  2.8190, -2.4030])\n",
    "Average logit difference: 0.775\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "\n",
    "- 5 out of 8 did not even reverse! But any positive logit differences are smaller.\n",
    "\n",
    "- That said, at least for these prompts, ***capitalisation of the next \"word-like\" token appears to depend fairly strongly on whether or not the *first* token (not token `0`/`<|endoftext|>`) was capitalised.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_residual_component(\n",
    "    corrupted_residual_component: Float[torch.Tensor, \"batch pos d_model\"],\n",
    "    hook,\n",
    "    pos,\n",
    "    clean_cache,\n",
    "):\n",
    "    corrupted_residual_component[:, pos, :] = clean_cache[hook.name][:, pos, :]\n",
    "    return corrupted_residual_component\n",
    "\n",
    "\n",
    "def normalize_patched_logit_diff(patched_logit_diff):\n",
    "    # Subtract corrupted logit diff to measure the improvement, divide by the total improvement from clean to corrupted to normalise\n",
    "    # 0 means zero change, negative means actively made worse, 1 means totally recovered clean performance, >1 means actively *improved* on clean performance\n",
    "    return (patched_logit_diff - average_logit_diff_corrupted) / (\n",
    "        original_average_logit_diff - average_logit_diff_corrupted\n",
    "    )\n",
    "\n",
    "\n",
    "patched_residual_stream_diff = torch.zeros(\n",
    "    model.cfg.n_layers, tokens.shape[1], device=device, dtype=torch.float32\n",
    ")\n",
    "for layer in range(model.cfg.n_layers):\n",
    "    for position in range(tokens.shape[1]):\n",
    "        hook_fn = partial(patch_residual_component, pos=position, clean_cache=cache)\n",
    "        patched_logits = model.run_with_hooks(\n",
    "            tokens_corrupted,\n",
    "            fwd_hooks=[(utils.get_act_name(\"resid_pre\", layer), hook_fn)],\n",
    "            return_type=\"logits\",\n",
    "        )\n",
    "        patched_logit_diff = logits_to_ave_logit_diff(patched_logits, answer_tokens)\n",
    "\n",
    "        patched_residual_stream_diff[layer, position] = normalize_patched_logit_diff(\n",
    "            patched_logit_diff\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Position: %{x}<br>Layer: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "x": [
          "<|endoftext|>_0",
          "F_1",
          "illing_2",
          " up_3",
          " to_4",
          " eleven_5",
          " tokens_6",
          "._7",
          "\n_8",
          "Go_9",
          "._10"
         ],
         "xaxis": "x",
         "yaxis": "y",
         "z": [
          [
           0,
           0.5821511745452881,
           0,
           0.023243695497512817,
           0,
           0.0281058456748724,
           0.08453238010406494,
           0.042449429631233215,
           0,
           0.13653677701950073,
           0
          ],
          [
           0,
           0.5800395011901855,
           0.004015620332211256,
           0.01984570547938347,
           0.0014104658039286733,
           0.017775794491171837,
           0.08513866364955902,
           0.03274916484951973,
           -0.00016078815679065883,
           0.13147635757923126,
           0.0019157580099999905
          ],
          [
           0,
           0.5788516402244568,
           0.02441863715648651,
           0.023181598633527756,
           0.003062239848077297,
           0.01777511276304722,
           0.08539318293333054,
           0.03404492884874344,
           -0.0005389279685914516,
           0.1337781697511673,
           0.007747940253466368
          ],
          [
           0,
           0.5671659708023071,
           0.03833431005477905,
           0.040134232491254807,
           0.005140266381204128,
           0.023218300193548203,
           0.08320295065641403,
           0.03901750221848488,
           -0.00013129913713783026,
           0.12269330769777298,
           0.019731130450963974
          ],
          [
           0,
           0.5467230081558228,
           0.04951566830277443,
           0.053165968507528305,
           0.005296770948916674,
           0.03289368376135826,
           0.07704004645347595,
           0.038350675255060196,
           0.0012763846898451447,
           0.08837412297725677,
           0.048978399485349655
          ],
          [
           0,
           0.49271321296691895,
           0.045390982180833817,
           0.05360071361064911,
           0.015166346915066242,
           0.03378443047404289,
           0.08039438724517822,
           0.03559661656618118,
           0.005639332812279463,
           0.054850105196237564,
           0.07902482897043228
          ],
          [
           0,
           0.26429110765457153,
           0.03372051939368248,
           0.05079576000571251,
           0.026735473424196243,
           0.03471575677394867,
           0.045070331543684006,
           0.03175241872668266,
           0.004404247738420963,
           0.035843320190906525,
           0.3482207953929901
          ],
          [
           0,
           0.2284768670797348,
           0.030387094244360924,
           0.030128013342618942,
           0.023487448692321777,
           0.023820899426937103,
           0.02923579327762127,
           0.023105235770344734,
           0.004816254135221243,
           0.028467504307627678,
           0.4610186219215393
          ],
          [
           0,
           0.17560739815235138,
           0.026596447452902794,
           0.02140214666724205,
           0.014528905041515827,
           0.016548531129956245,
           0.01789288967847824,
           0.016865750774741173,
           0.004336346406489611,
           0.021908123046159744,
           0.5907748341560364
          ],
          [
           0,
           0.08707857877016068,
           0.01703711971640587,
           0.013305461965501308,
           0.00841897539794445,
           0.01281371247023344,
           0.009219263680279255,
           0.009524987079203129,
           0.002968492219224572,
           0.011364792473614216,
           0.7813688516616821
          ],
          [
           0,
           0.03475034609436989,
           0.008352922275662422,
           0.005195275880396366,
           0.004405549261718988,
           0.006893052253872156,
           0.005807690322399139,
           0.004841554444283247,
           0.0020675284322351217,
           0.008834236301481724,
           0.8839426636695862
          ],
          [
           0,
           0.007639904972165823,
           0.004872009623795748,
           0.00245313229970634,
           0.0028255926445126534,
           0.004142331890761852,
           0.0030898810364305973,
           0.0016987527487799525,
           0.001216293778270483,
           0.006913733668625355,
           0.9466800689697266
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "cmid": 0,
         "colorscale": [
          [
           0,
           "rgb(103,0,31)"
          ],
          [
           0.1,
           "rgb(178,24,43)"
          ],
          [
           0.2,
           "rgb(214,96,77)"
          ],
          [
           0.3,
           "rgb(244,165,130)"
          ],
          [
           0.4,
           "rgb(253,219,199)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(209,229,240)"
          ],
          [
           0.7,
           "rgb(146,197,222)"
          ],
          [
           0.8,
           "rgb(67,147,195)"
          ],
          [
           0.9,
           "rgb(33,102,172)"
          ],
          [
           1,
           "rgb(5,48,97)"
          ]
         ]
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Logit Difference From Patched Residual Stream"
        },
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y",
         "title": {
          "text": "Position"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Layer"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt_position_labels = [\n",
    "    f\"{tok}_{i}\" for i, tok in enumerate(model.to_str_tokens(tokens[0]))\n",
    "]\n",
    "imshow(\n",
    "    patched_residual_stream_diff,\n",
    "    x=prompt_position_labels,\n",
    "    title=\"Logit Difference From Patched Residual Stream\",\n",
    "    labels={\"x\": \"Position\", \"y\": \"Layer\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "\n",
    "- **With all of the above caveats**\n",
    "  - It *does* appear that some of the contributory computation is happening on the first token, which is ordinarily capitalised.\n",
    "\n",
    "  - At around layers 5-8, the information is moved to the final token?\n",
    "    - Are the initial layers determining a \"capitalisation-state\" datum for the first token in the sequence, and using this to help determine the token following the full stop?\n",
    "\n",
    "  - Not much other evidence for this though. Attention heads in these layers seem to weakly affect logits directly. Let's have a squiz anyway:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heads in layers 5 - 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='max-width: 700px;'><h2>Layer 5 Logit Attribution Heads</h2><br/><div id=\"circuits-vis-3083e2aa-a054\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionHeads } from \"https://unpkg.com/circuitsvis@1.41.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-3083e2aa-a054\",\n",
       "      AttentionHeads,\n",
       "      {\"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9942885637283325, 0.00571140693500638, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9850571751594543, 0.0061165569350123405, 0.00882620271295309, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9815520644187927, 0.0013388711959123611, 0.0004478724440559745, 0.016661182045936584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9097299575805664, 0.00018105462368112057, 8.414781041210517e-05, 0.0037187624257057905, 0.08628606796264648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9556769132614136, 1.7937980373972096e-05, 5.7386860135011375e-05, 0.0005759498453699052, 0.008329251781105995, 0.035342540591955185, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9394962787628174, 0.00026076840003952384, 8.149913628585637e-05, 0.0005389423458836973, 0.0015480030560865998, 0.0018518541473895311, 0.05622268095612526, 0.0, 0.0, 0.0, 0.0], [0.9471215009689331, 0.0007826471701264381, 0.00042198447044938803, 0.0008184986654669046, 0.0025920975022017956, 0.0011492259800434113, 0.005057130008935928, 0.042056888341903687, 0.0, 0.0, 0.0], [0.9573463797569275, 0.028691371902823448, 0.004163576290011406, 0.00025893599377013743, 0.0007263709558174014, 7.981043745530769e-05, 0.0005852877511642873, 0.003717827145010233, 0.004430417902767658, 0.0, 0.0], [0.9169169068336487, 0.002273477613925934, 0.014835217036306858, 0.040665190666913986, 0.014612143859267235, 0.0009494086261838675, 0.001679575303569436, 0.00098349095787853, 0.00048184607294388115, 0.006602805107831955, 0.0], [0.9598423838615417, 0.0006549985846504569, 0.0003768949245568365, 0.001073160907253623, 0.004150689113885164, 0.0015748845180496573, 0.0005207359208725393, 3.3431810152251273e-05, 0.025011466816067696, 0.00551207410171628, 0.0012492889072746038]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9999802112579346, 1.98054713109741e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9999135732650757, 1.4670188193122158e-06, 8.502015407430008e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9997479319572449, 8.10465917311376e-06, 3.22686197762323e-08, 0.00024394039064645767, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9994139671325684, 8.820595098768536e-07, 6.226248405738488e-09, 4.750749837967305e-07, 0.000584693974815309, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9858306050300598, 3.233947438729956e-07, 1.6774528432961233e-08, 7.540023005958574e-08, 2.5191726308548823e-05, 0.014143864624202251, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9981051683425903, 3.501912715364597e-06, 1.0496709279550487e-07, 2.3612777511061722e-07, 7.454963792952185e-07, 2.3027700081001967e-05, 0.0018672639271244407, 0.0, 0.0, 0.0, 0.0], [0.998860239982605, 9.800346742849797e-05, 1.120300453294476e-06, 1.0860085239983164e-06, 4.6012743837309245e-07, 1.0679450497264042e-05, 7.047308463370427e-05, 0.0009579555480740964, 0.0, 0.0, 0.0], [0.9950032830238342, 0.0022791612427681684, 0.0003808382898569107, 2.6440751753398217e-05, 3.2684158668416785e-06, 6.691940143355168e-06, 4.414011709741317e-05, 2.1862822904950008e-05, 0.002234233543276787, 0.0, 0.0], [0.9996811151504517, 2.4109504010993987e-05, 6.2676763263880275e-06, 7.617914889124222e-06, 3.7865436297579436e-06, 2.097921424137894e-06, 1.7468729538450134e-06, 3.2048401976680907e-07, 2.2673796138406033e-06, 0.00027067921473644674, 0.0], [0.9994363188743591, 9.351606422569603e-05, 8.409873686332503e-08, 3.1695838060841197e-06, 1.0744331575551769e-06, 2.7229252737015486e-06, 5.252092591945257e-07, 1.293336815422208e-08, 0.0001853026042226702, 0.00013729660713579506, 0.0001400045439368114]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9938859343528748, 0.006114079616963863, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8630310297012329, 0.10156076401472092, 0.03540826588869095, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.71003258228302, 0.04609599709510803, 0.0904981791973114, 0.15337321162223816, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6700433492660522, 0.014654857106506824, 0.04413703456521034, 0.2579917907714844, 0.01317288912832737, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.578604519367218, 0.017451338469982147, 0.01638808287680149, 0.07711950689554214, 0.2620505690574646, 0.04838606342673302, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5228123068809509, 0.013038785196840763, 0.024311605840921402, 0.10094409435987473, 0.1464165598154068, 0.17473894357681274, 0.017737705260515213, 0.0, 0.0, 0.0, 0.0], [0.23532384634017944, 0.05589960888028145, 0.21906237304210663, 0.13591714203357697, 0.10570716857910156, 0.10455211251974106, 0.12927725911140442, 0.014260496012866497, 0.0, 0.0, 0.0], [0.6154345273971558, 0.09119554609060287, 0.09837938845157623, 0.02002369426190853, 0.023581745103001595, 0.023446759209036827, 0.034824732691049576, 0.0859793946146965, 0.0071342987939715385, 0.0, 0.0], [0.8442081809043884, 0.0036881864070892334, 0.001268175314180553, 0.01208013016730547, 0.0019336632685735822, 0.01130327396094799, 0.03418995812535286, 0.05028007552027702, 0.03377832844853401, 0.007270030211657286, 0.0], [0.7210861444473267, 0.0033110526856034994, 0.0036848639138042927, 0.008655291050672531, 0.0007534099277108908, 0.006643577478826046, 0.005995704792439938, 0.006399582140147686, 0.00806717574596405, 0.209785595536232, 0.025617554783821106]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9650188684463501, 0.03498117998242378, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7498757839202881, 0.20880739390850067, 0.041316818445920944, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7917858958244324, 0.09028099477291107, 0.08671145886182785, 0.031221678480505943, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8145531415939331, 0.06724623590707779, 0.06245800852775574, 0.04660637676715851, 0.009136113338172436, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7474309802055359, 0.039610572159290314, 0.09548969566822052, 0.05866247043013573, 0.015223540365695953, 0.043582733720541, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5502292513847351, 0.049129705876111984, 0.15578770637512207, 0.056201305240392685, 0.05381345376372337, 0.08109201490879059, 0.05374651029706001, 0.0, 0.0, 0.0, 0.0], [0.39463692903518677, 0.08940589427947998, 0.2037522792816162, 0.0723361149430275, 0.03761300817131996, 0.10921910405158997, 0.024573324248194695, 0.06846331059932709, 0.0, 0.0, 0.0], [0.31686508655548096, 0.1460617631673813, 0.2129591405391693, 0.06570911407470703, 0.031555209308862686, 0.03629675135016441, 0.012709964998066425, 0.12382660806179047, 0.054016340523958206, 0.0, 0.0], [0.4822891652584076, 0.019584733992815018, 0.02131650783121586, 0.035493187606334686, 0.020486876368522644, 0.021372070536017418, 0.038187265396118164, 0.05542141571640968, 0.2708861827850342, 0.03496254235506058, 0.0], [0.5530844330787659, 0.017516106367111206, 0.01228360366076231, 0.018231049180030823, 0.008632228709757328, 0.008470236323773861, 0.011486892588436604, 0.010911839082837105, 0.1640053540468216, 0.10188326239585876, 0.09349502623081207]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9844229817390442, 0.015577028505504131, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8259948492050171, 0.06540709733963013, 0.10859799385070801, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7792853116989136, 0.08426088839769363, 0.08368757367134094, 0.05276620760560036, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.35995492339134216, 0.02170845866203308, 0.1914188712835312, 0.3659355938434601, 0.0609821192920208, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4834975600242615, 0.03773331642150879, 0.2554037570953369, 0.17619334161281586, 0.035414401441812515, 0.01175764948129654, 0.0, 0.0, 0.0, 0.0, 0.0], [0.49152347445487976, 0.015485071577131748, 0.09917986392974854, 0.17155449092388153, 0.0681305006146431, 0.08170352131128311, 0.07242308557033539, 0.0, 0.0, 0.0, 0.0], [0.31956636905670166, 0.03167290613055229, 0.034655552357435226, 0.03413883224129677, 0.08753436803817749, 0.27610087394714355, 0.15836268663406372, 0.057968441396951675, 0.0, 0.0, 0.0], [0.5624706745147705, 0.027873508632183075, 0.02627180889248848, 0.019251365214586258, 0.04020358994603157, 0.08791811019182205, 0.11823977530002594, 0.10352431237697601, 0.014246843755245209, 0.0, 0.0], [0.7255633473396301, 0.0036840506363660097, 0.017930852249264717, 0.06166072189807892, 0.018221277743577957, 0.018864501267671585, 0.02409348264336586, 0.04543503746390343, 0.06624386459589005, 0.018302898854017258, 0.0], [0.5581796169281006, 0.0073244087398052216, 0.011692271567881107, 0.040434330701828, 0.0076015363447368145, 0.0065751755610108376, 0.004094523377716541, 0.00781786348670721, 0.011242775246500969, 0.303195983171463, 0.04184155911207199]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9917130470275879, 0.008286957629024982, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.999038815498352, 0.0007252910872921348, 0.00023595937818754464, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9982011318206787, 0.0014270540559664369, 6.611162461922504e-06, 0.00036514626117423177, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9895111918449402, 0.004533207509666681, 0.00024068761558737606, 0.0005072318017482758, 0.0052078175358474255, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9725893139839172, 0.0011723238276317716, 0.00010307574120815843, 9.701324597699568e-05, 0.0011332591529935598, 0.024905052036046982, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9929255247116089, 0.0019221295369789004, 0.00023069304006639868, 0.000406064122216776, 4.5238961320137605e-05, 0.001228643348440528, 0.0032418263144791126, 0.0, 0.0, 0.0, 0.0], [0.9095108509063721, 0.00977414846420288, 0.0002606365014798939, 0.004481100477278233, 0.004008331336081028, 0.007413659710437059, 0.02999553270637989, 0.03455565497279167, 0.0, 0.0, 0.0], [0.9394106268882751, 0.016572516411542892, 0.00039210609975270927, 0.00043100854963995516, 0.0005289746331982315, 0.007743137422949076, 0.014312359504401684, 0.008749895729124546, 0.011859310790896416, 0.0, 0.0], [0.9787884950637817, 0.0029181495774537325, 6.245556141948327e-05, 0.00017050084716174752, 6.67165732011199e-05, 0.0011006403947249055, 0.0005818451754748821, 0.0006649821880273521, 0.003528534434735775, 0.012117586098611355, 0.0], [0.8799020051956177, 0.01305160578340292, 1.477273599448381e-05, 0.001770327682606876, 0.0005061803385615349, 0.006947638466954231, 0.004560189321637154, 0.001248799730092287, 0.034704484045505524, 0.018565744161605835, 0.038728270679712296]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9245989322662354, 0.07540105283260345, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9296220541000366, 0.06915479898452759, 0.0012231561122462153, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7710710167884827, 0.0017632599920034409, 0.18792042136192322, 0.0392453595995903, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.36932867765426636, 0.004565937910228968, 0.05416479334235191, 0.5396386384963989, 0.03230193629860878, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.33458223938941956, 0.013902355916798115, 0.041432395577430725, 0.03426837548613548, 0.4961910545825958, 0.07962357252836227, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8528664112091064, 0.001335897366516292, 0.0005978310364298522, 0.0007349334773607552, 0.00432752538472414, 0.10492141544818878, 0.03521586209535599, 0.0, 0.0, 0.0, 0.0], [0.7694273591041565, 0.00018605984223540872, 3.7616660847561434e-05, 4.391797483549453e-05, 0.0002599926956463605, 0.002264130162075162, 0.1972210705280304, 0.030559781938791275, 0.0, 0.0, 0.0], [0.7665461897850037, 0.0006201863288879395, 0.00038476273766718805, 0.0009213127195835114, 0.0014319048495963216, 0.00519911153241992, 0.0126934964209795, 0.13390982151031494, 0.07829326391220093, 0.0, 0.0], [0.23264071345329285, 0.010507569648325443, 0.001100238529033959, 0.0008372389129363, 0.006628229282796383, 0.0013189440360292792, 0.007668175268918276, 0.04332214593887329, 0.6863561868667603, 0.009620624594390392, 0.0], [0.7854753136634827, 0.0001517673081252724, 0.00039679225301370025, 0.0002968961198348552, 0.00021488375205080956, 8.152530062943697e-05, 0.0007355191046372056, 6.727437721565366e-05, 0.0008542677969671786, 0.14705803990364075, 0.06466778367757797]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9900140762329102, 0.009985907934606075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5714961290359497, 0.11412908881902695, 0.31437477469444275, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3349592685699463, 0.017227724194526672, 0.6250232458114624, 0.022789761424064636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2739103436470032, 0.008019501343369484, 0.46029335260391235, 0.1978316456079483, 0.059945181012153625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6763873100280762, 0.07861557602882385, 0.18368226289749146, 0.032441381365060806, 0.017289845272898674, 0.01158361230045557, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7631232738494873, 0.015238364227116108, 0.10068219155073166, 0.06206940859556198, 0.032793253660202026, 0.007154676131904125, 0.018938779830932617, 0.0, 0.0, 0.0, 0.0], [0.785153329372406, 0.05086633563041687, 0.030682407319545746, 0.021555336192250252, 0.02094378136098385, 0.013385407626628876, 0.06719984114170074, 0.010213512927293777, 0.0, 0.0, 0.0], [0.9401795268058777, 0.02156401425600052, 0.0023900417145341635, 0.005278565920889378, 0.002159746829420328, 0.0023015623446553946, 0.014342397451400757, 0.0037062710616737604, 0.008077794685959816, 0.0, 0.0], [0.9342062473297119, 0.005660386756062508, 0.0025929652620106936, 0.0022663138806819916, 0.0035637568216770887, 0.0011002238607034087, 0.030340438708662987, 0.003724296111613512, 0.001345478231087327, 0.015199846588075161, 0.0], [0.8582659363746643, 0.0077982097864151, 0.002679179422557354, 0.003538656048476696, 0.003409055760130286, 0.0020100418478250504, 0.009958394803106785, 0.0017549553886055946, 0.006031316239386797, 0.08659081161022186, 0.017963392660021782]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9807250499725342, 0.01927492395043373, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9507316946983337, 0.021742578595876694, 0.02752566523849964, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9873598217964172, 0.006987467873841524, 0.0012965213973075151, 0.004356239922344685, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9622554183006287, 0.005197382997721434, 0.002623799489811063, 0.001863134209997952, 0.028060272336006165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9656546115875244, 0.003141767578199506, 0.0020544917788356543, 0.0011295601725578308, 0.00440813647583127, 0.023611536249518394, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9511581659317017, 0.007518642116338015, 0.0028443033806979656, 0.003323127282783389, 0.0017532212659716606, 0.0041406238451600075, 0.02926194667816162, 0.0, 0.0, 0.0, 0.0], [0.8825321197509766, 0.04540678858757019, 0.0075562517158687115, 0.014303299598395824, 0.004301532171666622, 0.005344798788428307, 0.02025425061583519, 0.02030097134411335, 0.0, 0.0, 0.0], [0.639665961265564, 0.24280047416687012, 0.02878987044095993, 0.040952928364276886, 0.01579604297876358, 0.0066763791255652905, 0.009214518591761589, 0.00564646115526557, 0.010457447730004787, 0.0, 0.0], [0.8779593110084534, 0.005548737943172455, 0.002873773220926523, 0.030035603791475296, 0.016600988805294037, 0.017354866489768028, 0.005180838983505964, 0.008363161236047745, 0.0058872331865131855, 0.030195411294698715, 0.0], [0.8385576009750366, 0.004965389613062143, 0.0006573197315447032, 0.0009915316477417946, 0.0010507189435884356, 0.004934804048389196, 0.0033230921253561974, 0.0007105694385245442, 0.07011480629444122, 0.05322287976741791, 0.02147131972014904]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9844877123832703, 0.015512258745729923, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9957542419433594, 0.004029684700071812, 0.00021601903426926583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9841346144676208, 0.009855781681835651, 0.002810955746099353, 0.0031987123657017946, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9706271290779114, 0.012003758922219276, 0.005625101272016764, 0.0078057218343019485, 0.0039382027462124825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9647090435028076, 0.008876295760273933, 0.002483733231201768, 0.003161525586619973, 0.008261321112513542, 0.012508138082921505, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9424718022346497, 0.008651377633213997, 0.007293728180229664, 0.010865970514714718, 0.005356155801564455, 0.010498007759451866, 0.014862945303320885, 0.0, 0.0, 0.0, 0.0], [0.8746085166931152, 0.008949334733188152, 0.012724518775939941, 0.008727658540010452, 0.008903569541871548, 0.015181930735707283, 0.03561614453792572, 0.03528832644224167, 0.0, 0.0, 0.0], [0.8825955986976624, 0.02706856094300747, 0.007040387485176325, 0.00678969407454133, 0.008643990382552147, 0.010034067556262016, 0.014119293540716171, 0.026996826753020287, 0.016711514443159103, 0.0, 0.0], [0.7770209908485413, 0.03605429828166962, 0.02936326339840889, 0.01054913830012083, 0.013861265033483505, 0.019245048984885216, 0.05099910870194435, 0.03521654009819031, 0.017142709344625473, 0.010547689162194729, 0.0], [0.8237453103065491, 0.02534112147986889, 0.013662808574736118, 0.017287103459239006, 0.007876857183873653, 0.01365669909864664, 0.015043084509670734, 0.015538378618657589, 0.019292742013931274, 0.03468964621424675, 0.013866264373064041]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9434818029403687, 0.05651815980672836, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9813222885131836, 0.008682897314429283, 0.009994729422032833, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9336372017860413, 0.0206088088452816, 0.01180870272219181, 0.03394525870680809, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8827005624771118, 0.017985550686717033, 0.025638576596975327, 0.04937592148780823, 0.02429945394396782, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8574131727218628, 0.02271086722612381, 0.06612502783536911, 0.01777600683271885, 0.005778761114925146, 0.030196258798241615, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8797461986541748, 0.009499125182628632, 0.011142722330987453, 0.009803632274270058, 0.008761321194469929, 0.0035326345823705196, 0.0775144025683403, 0.0, 0.0, 0.0, 0.0], [0.4916773736476898, 0.009433139115571976, 0.04029519483447075, 0.04382804408669472, 0.022873038426041603, 0.033668700605630875, 0.25484561920166016, 0.10337883979082108, 0.0, 0.0, 0.0], [0.6550564169883728, 0.025162842124700546, 0.021185442805290222, 0.04415188357234001, 0.014978529885411263, 0.05495661497116089, 0.04753769934177399, 0.10934143513441086, 0.027629101648926735, 0.0, 0.0], [0.5758194327354431, 0.02314908429980278, 0.02343928813934326, 0.0529322512447834, 0.020144421607255936, 0.018913105130195618, 0.060164183378219604, 0.06622558832168579, 0.03940891474485397, 0.11980375647544861, 0.0], [0.6171519160270691, 0.03729371353983879, 0.021610183641314507, 0.030887510627508163, 0.014010149985551834, 0.02092631906270981, 0.04479686915874481, 0.052270613610744476, 0.014117044396698475, 0.10364116728305817, 0.04329455643892288]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9564666748046875, 0.043533261865377426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9308562874794006, 0.008118391036987305, 0.061025217175483704, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8902059197425842, 0.02047516033053398, 0.013487651944160461, 0.07583122700452805, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8332592844963074, 0.006428509950637817, 0.0073728011921048164, 0.02868332341313362, 0.12425601482391357, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.841709315776825, 0.02124842442572117, 0.011041427962481976, 0.017132608219981194, 0.029282275587320328, 0.07958586513996124, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8394620418548584, 0.03550782427191734, 0.030709773302078247, 0.03399170935153961, 0.0143992705270648, 0.010551443323493004, 0.035377826541662216, 0.0, 0.0, 0.0, 0.0], [0.6601893305778503, 0.026399528607726097, 0.022261256352066994, 0.008054273203015327, 0.024053219705820084, 0.0037662882823497057, 0.019719144329428673, 0.23555700480937958, 0.0, 0.0, 0.0], [0.811265766620636, 0.01982942409813404, 0.0040920572355389595, 0.004260759335011244, 0.005592954810708761, 0.002715707989409566, 0.009473731741309166, 0.056062035262584686, 0.08670759946107864, 0.0, 0.0], [0.8080417513847351, 0.01143189612776041, 0.005861425306648016, 0.004529252648353577, 0.003484397428110242, 0.0026406843680888414, 0.0031315165106207132, 0.023037085309624672, 0.01652776263654232, 0.12131430953741074, 0.0], [0.8005682826042175, 0.01672833226621151, 0.009080983698368073, 0.01202823780477047, 0.010639672167599201, 0.0031658420339226723, 0.006560459267348051, 0.028439929708838463, 0.014504238963127136, 0.03700263425707817, 0.06128144636750221]]], \"attentionHeadNames\": [\"L5H0\", \"L5H1\", \"L5H2\", \"L5H3\", \"L5H4\", \"L5H5\", \"L5H6\", \"L5H7\", \"L5H8\", \"L5H9\", \"L5H10\", \"L5H11\"], \"tokens\": [\"<|endoftext|>\", \"F\", \"illing\", \" up\", \" to\", \" eleven\", \" tokens\", \".\", \"\\n\", \"Go\", \".\"], \"maskUpperTri\": true}\n",
       "    )\n",
       "    </script></div><div style='max-width: 700px;'><h2>Layer 6 Logit Attribution Heads</h2><br/><div id=\"circuits-vis-99d91f4e-ee96\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionHeads } from \"https://unpkg.com/circuitsvis@1.41.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-99d91f4e-ee96\",\n",
       "      AttentionHeads,\n",
       "      {\"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9879469275474548, 0.012053035199642181, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8546858429908752, 0.11916373670101166, 0.026150453835725784, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7140238881111145, 0.11860790103673935, 0.14537528157234192, 0.021992957219481468, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5252867937088013, 0.06614623963832855, 0.2239825576543808, 0.15390586853027344, 0.03067854978144169, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2754552364349365, 0.02727341465651989, 0.320636123418808, 0.18664313852787018, 0.15575642883777618, 0.0342356376349926, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21865691244602203, 0.01734430342912674, 0.07639491558074951, 0.17397820949554443, 0.13805916905403137, 0.3269120752811432, 0.048654407262802124, 0.0, 0.0, 0.0, 0.0], [0.7047392129898071, 0.0647052675485611, 0.03372536972165108, 0.013135421089828014, 0.012776704505085945, 0.024994133040308952, 0.051746491342782974, 0.0941774845123291, 0.0, 0.0, 0.0], [0.8141590356826782, 0.02533465251326561, 0.027555925771594048, 0.004611840937286615, 0.007710280362516642, 0.011585678905248642, 0.02675766684114933, 0.042955897748470306, 0.039329010993242264, 0.0, 0.0], [0.758795976638794, 0.016477782279253006, 0.007245437707751989, 0.005195681005716324, 0.003997538238763809, 0.013407223857939243, 0.010265505872666836, 0.03971315920352936, 0.118255615234375, 0.02664617821574211, 0.0], [0.710137665271759, 0.020607898011803627, 0.006823259871453047, 0.006477245129644871, 0.0020582196302711964, 0.004093525931239128, 0.00910263042896986, 0.012613645754754543, 0.03318347409367561, 0.1304924488067627, 0.06440994888544083]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9855793714523315, 0.014420575462281704, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8765270113945007, 0.016899732872843742, 0.10657329112291336, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5862444043159485, 0.0067022694274783134, 0.20813876390457153, 0.1989145576953888, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4971247911453247, 0.017672061920166016, 0.013353784568607807, 0.3928128778934479, 0.07903645932674408, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8600632548332214, 0.0033243545331060886, 0.0046395291574299335, 0.06531715393066406, 0.03850683569908142, 0.028148798272013664, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9294270277023315, 0.002303370041772723, 0.003914272878319025, 0.007018199190497398, 0.026298467069864273, 0.018031731247901917, 0.013006833381950855, 0.0, 0.0, 0.0, 0.0], [0.732328474521637, 0.05241535231471062, 0.05044683441519737, 0.04742230474948883, 0.03660591319203377, 0.00961899384856224, 0.03273162990808487, 0.03843051940202713, 0.0, 0.0, 0.0], [0.8176623582839966, 0.04462087154388428, 0.052391842007637024, 0.036130569875240326, 0.004711254965513945, 0.003225359134376049, 0.011524301953613758, 0.010041983798146248, 0.01969149149954319, 0.0, 0.0], [0.8595359921455383, 0.003960629925131798, 0.015408624894917011, 0.013230068609118462, 0.006282899994403124, 0.006405884865671396, 0.012627530843019485, 0.006597302388399839, 0.012165000662207603, 0.06378600001335144, 0.0], [0.3893134891986847, 0.00835314579308033, 0.009668176993727684, 0.00814756564795971, 0.004685335326939821, 0.0010199513053521514, 0.006814746651798487, 0.0011143684387207031, 0.026994915679097176, 0.5177140235900879, 0.026174303144216537]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9798679351806641, 0.0201320368796587, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9612846374511719, 0.0258332472294569, 0.012882057577371597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9646835327148438, 0.01713092438876629, 0.012230182997882366, 0.005955350119620562, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9656174182891846, 0.016033349558711052, 0.007097545079886913, 0.0026885089464485645, 0.00856315903365612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9216874837875366, 0.010754285380244255, 0.015510763972997665, 0.004892966244369745, 0.014431256800889969, 0.03272325545549393, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9001732468605042, 0.017115077003836632, 0.01752050593495369, 0.008830160833895206, 0.013001182116568089, 0.028381841257214546, 0.014978060498833656, 0.0, 0.0, 0.0, 0.0], [0.7418925762176514, 0.0169706791639328, 0.015747709199786186, 0.02301078289747238, 0.021237250417470932, 0.04260938614606857, 0.025573119521141052, 0.11295858770608902, 0.0, 0.0, 0.0], [0.7936511635780334, 0.033837784081697464, 0.019455356523394585, 0.025771386921405792, 0.012593535706400871, 0.028426120057702065, 0.021215101704001427, 0.0529344268143177, 0.01211518794298172, 0.0, 0.0], [0.8422470688819885, 0.01810692995786667, 0.011770317330956459, 0.013285531662404537, 0.013804157264530659, 0.017783813178539276, 0.01584555022418499, 0.04176047816872597, 0.015155429020524025, 0.010240701958537102, 0.0], [0.7848755121231079, 0.012897028587758541, 0.014961274340748787, 0.015637202188372612, 0.012076358310878277, 0.016299394890666008, 0.02517831325531006, 0.03339459002017975, 0.008928468450903893, 0.010938199236989021, 0.06481362879276276]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9930934906005859, 0.006906513124704361, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9880234003067017, 0.006598100531846285, 0.005378520116209984, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9787590503692627, 0.005351553671061993, 0.0053444416262209415, 0.01054505817592144, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9113132953643799, 0.01066403929144144, 0.014854480512440205, 0.047037456184625626, 0.016130760312080383, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7939536571502686, 0.013588742353022099, 0.048729024827480316, 0.07736807316541672, 0.029478196054697037, 0.03688230365514755, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8293887376785278, 0.005299008451402187, 0.023495223373174667, 0.03589613363146782, 0.013977386988699436, 0.05764656141400337, 0.03429692983627319, 0.0, 0.0, 0.0, 0.0], [0.6023293733596802, 0.013454397208988667, 0.050525762140750885, 0.04303235560655594, 0.03365485370159149, 0.1372111737728119, 0.03941502422094345, 0.08037710189819336, 0.0, 0.0, 0.0], [0.6445518136024475, 0.03176406770944595, 0.0533357635140419, 0.027515487745404243, 0.010977639816701412, 0.051470328122377396, 0.02856222167611122, 0.11070943623781204, 0.04111318662762642, 0.0, 0.0], [0.6709789633750916, 0.015213693492114544, 0.01919517107307911, 0.03984556347131729, 0.014899101108312607, 0.04219837859272957, 0.04242895916104317, 0.0775071457028389, 0.04519430175423622, 0.032538704574108124, 0.0], [0.834670901298523, 0.005660069640725851, 0.011202553287148476, 0.019532931968569756, 0.0032980639953166246, 0.011843441985547543, 0.012978455051779747, 0.009543834254145622, 0.012432308867573738, 0.03187333419919014, 0.046964190900325775]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9368301630020142, 0.06316976249217987, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8858307600021362, 0.044109802693128586, 0.07005949318408966, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8324055671691895, 0.02227933332324028, 0.07149603217840195, 0.07381902635097504, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8181264400482178, 0.03083707205951214, 0.060626037418842316, 0.04396374151110649, 0.04644674435257912, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5603027939796448, 0.014371810480952263, 0.07688961923122406, 0.03585001453757286, 0.01703481376171112, 0.29555097222328186, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5699928998947144, 0.002471216721460223, 0.02235535904765129, 0.047249965369701385, 0.014066614210605621, 0.12948180735111237, 0.21438215672969818, 0.0, 0.0, 0.0, 0.0], [0.2832488715648651, 0.005563728511333466, 0.014974129386246204, 0.041583042591810226, 0.013601243495941162, 0.13986097276210785, 0.38312700390815735, 0.1180410385131836, 0.0, 0.0, 0.0], [0.379808634519577, 0.0031654327176511288, 0.010740612633526325, 0.013691430911421776, 0.004322247579693794, 0.17079193890094757, 0.30922186374664307, 0.06495022028684616, 0.04330761358141899, 0.0, 0.0], [0.2795732915401459, 0.012249081395566463, 0.008660518564283848, 0.0681142657995224, 0.02249556966125965, 0.09272804111242294, 0.30013465881347656, 0.13568034768104553, 0.052383337169885635, 0.02798093482851982, 0.0], [0.6099497675895691, 0.020738869905471802, 0.010081058368086815, 0.04998798668384552, 0.013546661473810673, 0.034253545105457306, 0.13210995495319366, 0.02270941622555256, 0.03310753032565117, 0.03377234935760498, 0.039742834866046906]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9803902506828308, 0.01960974931716919, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9514603018760681, 0.022668106481432915, 0.02587154321372509, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9313744306564331, 0.014388573355972767, 0.027072029188275337, 0.027164990082383156, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.803004801273346, 0.01587020792067051, 0.03443484380841255, 0.03963451460003853, 0.10705571621656418, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8276258707046509, 0.01662035845220089, 0.027473684400320053, 0.026755187660455704, 0.05112924799323082, 0.05039572715759277, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8115530014038086, 0.008503983728587627, 0.026277877390384674, 0.01780373975634575, 0.035971496254205704, 0.04852002114057541, 0.051369842141866684, 0.0, 0.0, 0.0, 0.0], [0.60722815990448, 0.029848601669073105, 0.032909851521253586, 0.01729634404182434, 0.05279150605201721, 0.041286222636699677, 0.09789171069860458, 0.1207476481795311, 0.0, 0.0, 0.0], [0.7309470176696777, 0.023624172434210777, 0.018432600423693657, 0.020867951214313507, 0.023939602077007294, 0.027227770537137985, 0.031008770689368248, 0.081729955971241, 0.042222168296575546, 0.0, 0.0], [0.7146313786506653, 0.007866115309298038, 0.009109572507441044, 0.008703065104782581, 0.008030488155782223, 0.01668272167444229, 0.03240325301885605, 0.06469922512769699, 0.10211023688316345, 0.035763952881097794, 0.0], [0.6116308569908142, 0.016430268064141273, 0.014988783746957779, 0.016113262623548508, 0.01722005382180214, 0.018333643674850464, 0.04156005382537842, 0.016092561185359955, 0.03617822006344795, 0.1365509331226349, 0.0749012678861618]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9191070199012756, 0.08089295029640198, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9630531668663025, 0.010035564191639423, 0.026911353692412376, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9473873376846313, 0.0057082888670265675, 0.013139529153704643, 0.0337647870182991, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9531250596046448, 0.005074365064501762, 0.006646689493209124, 0.020273840054869652, 0.014879944734275341, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9239432215690613, 0.007638318929821253, 0.004097977187484503, 0.010745546780526638, 0.003962957300245762, 0.04961206763982773, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8940965533256531, 0.00753945205360651, 0.007110963575541973, 0.004049530252814293, 0.0019083673832938075, 0.004173205234110355, 0.08112189918756485, 0.0, 0.0, 0.0, 0.0], [0.8026233315467834, 0.01665659248828888, 0.015396807342767715, 0.014067387208342552, 0.005528192967176437, 0.012389020062983036, 0.04511396959424019, 0.08822464197874069, 0.0, 0.0, 0.0], [0.8561146855354309, 0.012152338400483131, 0.010480311699211597, 0.009817163459956646, 0.0012145942309871316, 0.002710498170927167, 0.01268388144671917, 0.02805725485086441, 0.0667693018913269, 0.0, 0.0], [0.8993465304374695, 0.010281727649271488, 0.005975145380944014, 0.004571075085550547, 0.0010371665703132749, 0.005881959572434425, 0.00345345726236701, 0.009615002200007439, 0.01865002140402794, 0.04118794575333595, 0.0], [0.7643612623214722, 0.018559539690613747, 0.011886529624462128, 0.013274773955345154, 0.007506558671593666, 0.006640780717134476, 0.008198459632694721, 0.019754381850361824, 0.05672658234834671, 0.03257963806390762, 0.060511551797389984]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9931473135948181, 0.006852699443697929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8916088342666626, 0.016463281586766243, 0.09192784875631332, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7811918258666992, 0.027739819139242172, 0.11753851175308228, 0.07352987676858902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6200972199440002, 0.012788807973265648, 0.06194908544421196, 0.20644839107990265, 0.09871650487184525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3877643346786499, 0.012299762107431889, 0.0973178818821907, 0.28636160492897034, 0.1206263080239296, 0.09563013166189194, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4997994601726532, 0.007230025716125965, 0.03480403870344162, 0.1705234795808792, 0.058798789978027344, 0.0705779418349266, 0.1582663357257843, 0.0, 0.0, 0.0, 0.0], [0.19061970710754395, 0.005015910603106022, 0.03783722594380379, 0.15765148401260376, 0.07330238819122314, 0.15216569602489471, 0.31337082386016846, 0.07003677636384964, 0.0, 0.0, 0.0], [0.14796419441699982, 0.002487446879968047, 0.029524901881814003, 0.10276895761489868, 0.10188589245080948, 0.1631886512041092, 0.2922608554363251, 0.15200276672840118, 0.007916301488876343, 0.0, 0.0], [0.4126562774181366, 0.019353384152054787, 0.02009143866598606, 0.05097835883498192, 0.05128035694360733, 0.055613696575164795, 0.1337660551071167, 0.1943884938955307, 0.043704334646463394, 0.018167579546570778, 0.0], [0.3779292106628418, 0.02318274974822998, 0.0724354237318039, 0.09053324162960052, 0.01873599924147129, 0.016851332038640976, 0.03259671851992607, 0.022167904302477837, 0.015184173360466957, 0.2567581236362457, 0.07362507283687592]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9909195899963379, 0.009080463089048862, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7026703357696533, 0.25706711411476135, 0.04026256874203682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.632542610168457, 0.0626978650689125, 0.2747807502746582, 0.029978716745972633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19258831441402435, 0.008942211978137493, 0.03844098001718521, 0.7221317291259766, 0.03789670765399933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4055822491645813, 0.08088342100381851, 0.0332467257976532, 0.24152079224586487, 0.18513844907283783, 0.053628336638212204, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6224337220191956, 0.013527154922485352, 0.012683921493589878, 0.05065028741955757, 0.037827908992767334, 0.2150305211544037, 0.0478464737534523, 0.0, 0.0, 0.0, 0.0], [0.4429243803024292, 0.03815622255206108, 0.03131682053208351, 0.040342628955841064, 0.028793849050998688, 0.1395616978406906, 0.24883434176445007, 0.030069993808865547, 0.0, 0.0, 0.0], [0.4762977957725525, 0.0086149787530303, 0.008188195526599884, 0.021082157269120216, 0.01034866739064455, 0.023867810145020485, 0.04589925333857536, 0.38665714859962463, 0.019044019281864166, 0.0, 0.0], [0.8090929985046387, 0.0030813422054052353, 0.000852391414809972, 0.003804131643846631, 0.002644298831000924, 0.005566793959587812, 0.010361121036112309, 0.05652083456516266, 0.10206829756498337, 0.006007764488458633, 0.0], [0.6251749992370605, 0.0027442181017249823, 0.001053566113114357, 0.0013981396332383156, 0.0017530564218759537, 0.0025316919200122356, 0.003819151083007455, 0.0014222431927919388, 0.008879327215254307, 0.33366408944129944, 0.017559541389346123]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9989235997200012, 0.0010763750178739429, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9998854398727417, 4.398054807097651e-05, 7.05959610058926e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9887528419494629, 3.4860386222135276e-05, 4.760048977914266e-05, 0.011164710856974125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9988068342208862, 3.798106263275258e-05, 2.0513061826932244e-05, 6.82226618664572e-06, 0.0011278650490567088, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8657769560813904, 6.271442543948069e-05, 1.3480030247592367e-05, 3.419390623093932e-06, 6.994378054514527e-05, 0.13407345116138458, 0.0, 0.0, 0.0, 0.0, 0.0], [0.994596540927887, 0.000515943334903568, 5.632728061755188e-05, 1.66397076100111e-05, 2.0536137981252978e-06, 0.00024069359642453492, 0.004571885336190462, 0.0, 0.0, 0.0, 0.0], [0.9831060767173767, 0.0035136458463966846, 0.0004303561872802675, 0.0006917189457453787, 0.00014244373596739024, 0.002244295086711645, 0.005240210331976414, 0.004631336312741041, 0.0, 0.0, 0.0], [0.9808592200279236, 0.006955299526453018, 0.00746893510222435, 0.00010830388055182993, 3.9735798054607585e-05, 0.0001971400051843375, 0.0034275613725185394, 0.00013884177315048873, 0.0008049846510402858, 0.0, 0.0], [0.9995042085647583, 0.00010910639684880152, 2.1298861611285247e-05, 1.6631938137834368e-07, 5.289519577900137e-08, 3.3628886740189046e-05, 3.7559406337095425e-05, 5.509054517460754e-06, 2.0135687009315006e-05, 0.0002683457569219172, 0.0], [0.9879680871963501, 0.001012379303574562, 2.27413656830322e-05, 0.00018486916087567806, 1.4968096365919337e-05, 0.001367810182273388, 0.00013569527072831988, 6.241845312615624e-06, 0.007625107653439045, 0.00020879610383417457, 0.0014533535577356815]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9626749753952026, 0.037325046956539154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.989006519317627, 0.004168455954641104, 0.0068250130861997604, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9755326509475708, 0.006390481721609831, 0.005397857166826725, 0.01267901062965393, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9747910499572754, 0.003615687834098935, 0.0023299262393265963, 0.004931256640702486, 0.014332183636724949, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8840371370315552, 0.000822568079456687, 0.0006835007225163281, 0.0010233789216727018, 0.004288000520318747, 0.10914532095193863, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9235352277755737, 0.0026768737006932497, 0.001148914685472846, 0.0025172526948153973, 0.003310403786599636, 0.04574701562523842, 0.021064352244138718, 0.0, 0.0, 0.0, 0.0], [0.8239946365356445, 0.0008031174656935036, 0.0017055434873327613, 0.0017302545020356774, 0.002484130673110485, 0.08665981888771057, 0.02418285608291626, 0.05843968689441681, 0.0, 0.0, 0.0], [0.877816379070282, 0.0011620389996096492, 0.0032494012266397476, 0.0050129066221416, 0.0032985550351440907, 0.048387181013822556, 0.022292396053671837, 0.020719964057207108, 0.018061237409710884, 0.0, 0.0], [0.788780152797699, 0.006151481531560421, 0.008517861366271973, 0.005820216611027718, 0.013880028389394283, 0.0630919337272644, 0.03433659300208092, 0.038112569600343704, 0.02377885952591896, 0.017530348151922226, 0.0], [0.9192832708358765, 0.0014625340700149536, 0.0013005405198782682, 0.001729084295220673, 0.0023863695096224546, 0.01881331391632557, 0.013954659923911095, 0.006401896942406893, 0.01871730200946331, 0.008053547702729702, 0.007897491566836834]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9832093119621277, 0.01679074950516224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8814585208892822, 0.023731868714094162, 0.09480960667133331, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7899490594863892, 0.04032246023416519, 0.0995434820652008, 0.07018498331308365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5445531606674194, 0.037241317331790924, 0.07028154283761978, 0.1756884604692459, 0.17223556339740753, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20858660340309143, 0.02549908123910427, 0.42126893997192383, 0.2523137032985687, 0.08012492954730988, 0.012206780724227428, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4680548906326294, 0.029914982616901398, 0.1619902402162552, 0.1329398900270462, 0.061877891421318054, 0.10930544137954712, 0.03591667115688324, 0.0, 0.0, 0.0, 0.0], [0.7999772429466248, 0.046031635254621506, 0.013551851734519005, 0.010668179020285606, 0.015858901664614677, 0.049734439700841904, 0.015705080702900887, 0.04847269505262375, 0.0, 0.0, 0.0], [0.8829613924026489, 0.016035517677664757, 0.003139304229989648, 0.001979388762265444, 0.0036140664014965296, 0.03717654198408127, 0.0190227460116148, 0.02299250289797783, 0.013078556396067142, 0.0, 0.0], [0.8121566772460938, 0.004504426848143339, 0.00785390567034483, 0.005278104916214943, 0.011021066457033157, 0.007774287834763527, 0.00935970339924097, 0.031207654625177383, 0.06552349776029587, 0.045320797711610794, 0.0], [0.6487200260162354, 0.010131558403372765, 0.008117178454995155, 0.003681819885969162, 0.005103339906781912, 0.006044656969606876, 0.005230872891843319, 0.002356950892135501, 0.022984346374869347, 0.2349647581577301, 0.05266450345516205]]], \"attentionHeadNames\": [\"L6H0\", \"L6H1\", \"L6H2\", \"L6H3\", \"L6H4\", \"L6H5\", \"L6H6\", \"L6H7\", \"L6H8\", \"L6H9\", \"L6H10\", \"L6H11\"], \"tokens\": [\"<|endoftext|>\", \"F\", \"illing\", \" up\", \" to\", \" eleven\", \" tokens\", \".\", \"\\n\", \"Go\", \".\"], \"maskUpperTri\": true}\n",
       "    )\n",
       "    </script></div><div style='max-width: 700px;'><h2>Layer 7 Logit Attribution Heads</h2><br/><div id=\"circuits-vis-5de7cc16-48a2\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionHeads } from \"https://unpkg.com/circuitsvis@1.41.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-5de7cc16-48a2\",\n",
       "      AttentionHeads,\n",
       "      {\"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.969440221786499, 0.030559822916984558, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.861224889755249, 0.11780223995447159, 0.02097279392182827, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6475533843040466, 0.08728937059640884, 0.2135518193244934, 0.05160541087388992, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5575770139694214, 0.012821586802601814, 0.0594729483127594, 0.3104569613933563, 0.059671420603990555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.055675964802503586, 0.0007660628180019557, 0.16000494360923767, 0.41396385431289673, 0.31247326731681824, 0.057115837931632996, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12672363221645355, 0.0023123016580939293, 0.019709045067429543, 0.049716800451278687, 0.13698992133140564, 0.6343358159065247, 0.03021242283284664, 0.0, 0.0, 0.0, 0.0], [0.7443408370018005, 0.004643515218049288, 0.0017860516672953963, 0.002305928384885192, 0.013573388569056988, 0.05147041380405426, 0.17232456803321838, 0.009555337950587273, 0.0, 0.0, 0.0], [0.8042909502983093, 0.0010423380881547928, 0.0015444306191056967, 0.0023565918672829866, 0.0027106842026114464, 0.016490627080202103, 0.04144249111413956, 0.08508496731519699, 0.04503695294260979, 0.0, 0.0], [0.3864513635635376, 0.00353700527921319, 0.0009802408749237657, 0.002134472131729126, 0.002652945229783654, 0.005052764900028706, 0.00929712038487196, 0.14975890517234802, 0.43785083293914795, 0.0022843792103230953, 0.0], [0.2372901439666748, 0.007077276706695557, 0.004657247103750706, 0.006788874510675669, 0.0042529297061264515, 0.007430806756019592, 0.00617757486179471, 0.000519795052241534, 0.0043011498637497425, 0.7126216888427734, 0.008882408030331135]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9949511289596558, 0.005048825871199369, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9899910688400269, 0.003093142295256257, 0.006915826816111803, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9597736597061157, 0.007146781776100397, 0.0034606046974658966, 0.029618948698043823, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9767280220985413, 0.005425203125923872, 0.0114226583391428, 0.003191090654581785, 0.0032330446410924196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9797677397727966, 0.002347228117287159, 0.004213857930153608, 0.002654491923749447, 0.0018275367328897119, 0.009189152158796787, 0.0, 0.0, 0.0, 0.0, 0.0], [0.961775541305542, 0.0007598637021146715, 0.0009749624296091497, 0.0005064149154350162, 0.00033571451785974205, 0.0018280267249792814, 0.03381943702697754, 0.0, 0.0, 0.0, 0.0], [0.9542074799537659, 0.0017962863203138113, 0.011287413537502289, 0.002547638025134802, 0.0011854986660182476, 0.006389304995536804, 0.010741055943071842, 0.011845262721180916, 0.0, 0.0, 0.0], [0.9807046055793762, 0.00020256490097381175, 0.001128024305216968, 0.0007204103749245405, 0.0002605938061606139, 0.0029275049455463886, 0.004109614063054323, 0.005691509693861008, 0.004255099222064018, 0.0, 0.0], [0.9168779253959656, 0.003696811618283391, 0.016305554658174515, 0.011722597293555737, 0.008119583129882812, 0.0088402284309268, 0.006667772773653269, 0.009270268492400646, 0.01099278125911951, 0.007506430149078369, 0.0], [0.8852344155311584, 0.002627423033118248, 0.0070947385393083096, 0.0035569409374147654, 0.003932990599423647, 0.007807596120983362, 0.009285842068493366, 0.003888858947902918, 0.00408706022426486, 0.0031791788060218096, 0.06930477172136307]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9985080361366272, 0.0014919883105903864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9996917247772217, 1.79332637344487e-05, 0.0002904061402659863, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9983240962028503, 4.7965339035727084e-05, 0.0002005035348702222, 0.0014273850247263908, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9988117218017578, 1.351832088403171e-05, 5.2465438784565777e-05, 1.811404581530951e-05, 0.0011040638200938702, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9916830062866211, 4.144075774092926e-06, 1.2372220226097852e-05, 3.7743252505606506e-06, 0.0002781206276267767, 0.008018461056053638, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9968898892402649, 4.2131738155148923e-05, 6.12376315984875e-05, 2.5063873181352392e-05, 7.802619802532718e-05, 0.0004711757064796984, 0.0024324916303157806, 0.0, 0.0, 0.0, 0.0], [0.995913565158844, 0.0006052041426301003, 0.000439588213339448, 7.877505413489416e-05, 9.137150482274592e-05, 0.000818661181256175, 0.0014219050062820315, 0.0006309030577540398, 0.0, 0.0, 0.0], [0.9988229870796204, 0.0003268711152486503, 0.00035596927045844495, 5.009382675780216e-06, 1.68199712788919e-05, 3.360548726050183e-05, 0.0002473997010383755, 2.6959462047670968e-05, 0.00016439780301880091, 0.0, 0.0], [0.9975905418395996, 3.54483381670434e-05, 0.00037181988591328263, 5.2995474106865004e-05, 9.280227095587179e-05, 0.00012482408783398569, 0.000695502501912415, 0.0002746102400124073, 0.00020653349929489195, 0.0005549989291466773, 0.0], [0.9911894798278809, 8.011019963305444e-05, 0.0002485328004695475, 5.1315575547050685e-05, 2.5387093046447262e-05, 0.0013732918305322528, 0.0004185678262729198, 5.5773998610675335e-06, 0.0026674980763345957, 0.00016344303730875254, 0.0037768406327813864]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9906657934188843, 0.009334246627986431, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9418341517448425, 0.024964749813079834, 0.03320103511214256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9348510503768921, 0.016204455867409706, 0.028187965974211693, 0.020756622776389122, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9172782897949219, 0.010764440521597862, 0.030631722882390022, 0.030818434432148933, 0.010507163591682911, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.888765811920166, 0.006686878390610218, 0.013822539709508419, 0.017060283571481705, 0.04016897454857826, 0.033495526760816574, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8311873078346252, 0.006135895848274231, 0.01192668080329895, 0.022357910871505737, 0.04702119156718254, 0.03897072747349739, 0.04240022972226143, 0.0, 0.0, 0.0, 0.0], [0.881422221660614, 0.00967311393469572, 0.012968892231583595, 0.013467289507389069, 0.014697447419166565, 0.022328199818730354, 0.0258239284157753, 0.019618958234786987, 0.0, 0.0, 0.0], [0.9061009883880615, 0.008475271984934807, 0.010115201584994793, 0.0057774814777076244, 0.0033156550489366055, 0.008304682560265064, 0.023787647485733032, 0.0210697203874588, 0.013053216971457005, 0.0, 0.0], [0.9146355986595154, 0.0044737099669873714, 0.007398210931569338, 0.008970518596470356, 0.006633311044424772, 0.00645602960139513, 0.008053760975599289, 0.017987053841352463, 0.01674775965511799, 0.00864400528371334, 0.0], [0.8703421950340271, 0.006742491386830807, 0.006571607664227486, 0.00850432924926281, 0.003765131114050746, 0.003062374424189329, 0.005917355418205261, 0.004974738694727421, 0.016824476420879364, 0.047447435557842255, 0.0258479006588459]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9958237409591675, 0.0041762967593967915, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9690806269645691, 0.027716534212231636, 0.0032029286958277225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9545215964317322, 0.025323789566755295, 0.014533030800521374, 0.005621653515845537, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.937112033367157, 0.018908003345131874, 0.024399258196353912, 0.006660948973149061, 0.012919762171804905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8375532031059265, 0.013669461011886597, 0.03963088244199753, 0.012669231742620468, 0.05918370932340622, 0.037293463945388794, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4244879186153412, 0.03186570852994919, 0.09161804616451263, 0.07159627228975296, 0.0835210308432579, 0.25551775097846985, 0.041393328458070755, 0.0, 0.0, 0.0, 0.0], [0.7031736373901367, 0.061779893934726715, 0.039887040853500366, 0.029092783108353615, 0.03783327341079712, 0.032665498554706573, 0.03828813135623932, 0.057279784232378006, 0.0, 0.0, 0.0], [0.9395541548728943, 0.005984717980027199, 0.004273122176527977, 0.0030498376581817865, 0.0016842834884300828, 0.002838418586179614, 0.004441570956259966, 0.016706017777323723, 0.02146795578300953, 0.0, 0.0], [0.9768771529197693, 0.0031688720919191837, 0.002602266613394022, 0.0009087771759368479, 0.000519353081472218, 0.0017013340257108212, 0.0017159120179712772, 0.0031752202194184065, 0.006458173040300608, 0.002872988348826766, 0.0], [0.8504177331924438, 0.007151434198021889, 0.0025017880834639072, 0.0016875492874532938, 0.0013564586406573653, 0.0014878829242661595, 0.0024856128729879856, 0.0041780113242566586, 0.005837145261466503, 0.06457123160362244, 0.05832522734999657]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9931939840316772, 0.006805945187807083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9502114057540894, 0.020696492865681648, 0.029092082753777504, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8184444308280945, 0.009947666898369789, 0.08247487246990204, 0.08913306891918182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8332523703575134, 0.006457276176661253, 0.02635207027196884, 0.08953969180583954, 0.04439865052700043, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6605935096740723, 0.006423494778573513, 0.04407179355621338, 0.1497340351343155, 0.11022770404815674, 0.028949439525604248, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7955595850944519, 0.0021756296046078205, 0.020302044227719307, 0.04816321283578873, 0.05602829530835152, 0.03089737705886364, 0.046873822808265686, 0.0, 0.0, 0.0, 0.0], [0.7922675609588623, 0.006787546910345554, 0.03466837480664253, 0.03381263092160225, 0.022090891376137733, 0.023310678079724312, 0.04533825442194939, 0.0417240709066391, 0.0, 0.0, 0.0], [0.905143678188324, 0.0037574360612779856, 0.008245774544775486, 0.0050690690986812115, 0.005442529451102018, 0.005804628599435091, 0.032880187034606934, 0.020571298897266388, 0.013085480779409409, 0.0, 0.0], [0.6648845672607422, 0.008084536530077457, 0.014284699223935604, 0.019624246284365654, 0.01668682135641575, 0.02147378958761692, 0.04537339508533478, 0.09830278158187866, 0.08474606275558472, 0.02653910219669342, 0.0], [0.7900499105453491, 0.006341086700558662, 0.011559028178453445, 0.009565955959260464, 0.005973217077553272, 0.010647608898580074, 0.023549390956759453, 0.012372132390737534, 0.02620171196758747, 0.08068347722291946, 0.023056399077177048]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9869400858879089, 0.013059908524155617, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9936657547950745, 0.0033163989428430796, 0.003017876762896776, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9682591557502747, 0.005837069358676672, 0.008284028619527817, 0.01761985383927822, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9548704028129578, 0.005663308314979076, 0.011418339796364307, 0.011598649434745312, 0.016449300572276115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9041303992271423, 0.0027438118122518063, 0.005730174016207457, 0.011824425309896469, 0.009149149991571903, 0.06642194837331772, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9207250475883484, 0.0016236687079071999, 0.005159445572644472, 0.007719486951828003, 0.008334450423717499, 0.019660597667098045, 0.03677740693092346, 0.0, 0.0, 0.0, 0.0], [0.746177077293396, 0.00511852977797389, 0.01594923436641693, 0.01661774516105652, 0.021441642194986343, 0.0270845890045166, 0.08412285149097443, 0.083488330245018, 0.0, 0.0, 0.0], [0.8546339869499207, 0.002024924848228693, 0.0075050340965390205, 0.011134389787912369, 0.012880655936896801, 0.01979716867208481, 0.03239629417657852, 0.038429271429777145, 0.021198254078626633, 0.0, 0.0], [0.6748045682907104, 0.003865449922159314, 0.02743716910481453, 0.030999310314655304, 0.04418743774294853, 0.06270745396614075, 0.06100595369935036, 0.049163948744535446, 0.027888579294085503, 0.017940163612365723, 0.0], [0.7334545254707336, 0.007571772206574678, 0.03264409676194191, 0.02212885022163391, 0.04109485447406769, 0.027585815638303757, 0.036717046052217484, 0.025441965088248253, 0.018838483840227127, 0.026918504387140274, 0.027604056522250175]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.994376540184021, 0.005623531062155962, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9968204498291016, 0.001309455605223775, 0.0018700910732150078, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9892832040786743, 0.0018432075157761574, 0.0038217196706682444, 0.005051929969340563, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.936187207698822, 0.0007260273559950292, 0.003464530222117901, 0.003041111631318927, 0.05658109858632088, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9946454763412476, 0.00017470677266828716, 0.000363246479537338, 0.0002573615638539195, 0.0006722932448610663, 0.0038869238924235106, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9676432609558105, 0.0016879456816241145, 0.004121202975511551, 0.0016378216678276658, 0.0028475148137658834, 0.005649813450872898, 0.016412561759352684, 0.0, 0.0, 0.0, 0.0], [0.8676099181175232, 0.003518499433994293, 0.013883724808692932, 0.010097406804561615, 0.024303602054715157, 0.017244789749383926, 0.02028818242251873, 0.04305383563041687, 0.0, 0.0, 0.0], [0.9692688584327698, 0.0055168443359434605, 0.003914198838174343, 0.0007982763927429914, 0.001744717825204134, 0.0029642742592841387, 0.005872972775250673, 0.0062836953438818455, 0.0036361394450068474, 0.0, 0.0], [0.9047182202339172, 0.0043475013226270676, 0.003518156474456191, 0.0022034102585166693, 0.007916644215583801, 0.018911439925432205, 0.01660938188433647, 0.017979668453335762, 0.012187475338578224, 0.01160806231200695, 0.0], [0.8818873167037964, 0.007726258132606745, 0.00896892137825489, 0.008756971918046474, 0.017191117629408836, 0.007675520610064268, 0.008021814748644829, 0.0024754449259489775, 0.008952416479587555, 0.014449954964220524, 0.033894289284944534]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.996942937374115, 0.003057018853724003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7194892168045044, 0.1713651716709137, 0.10914557427167892, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7092273235321045, 0.037397127598524094, 0.20308902859687805, 0.05028656870126724, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3542870581150055, 0.0236178208142519, 0.09808974713087082, 0.47226792573928833, 0.05173743888735771, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.25552335381507874, 0.017447473481297493, 0.23963269591331482, 0.3076755106449127, 0.15990206599235535, 0.019818861037492752, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3989400267601013, 0.007773338817059994, 0.059257622808218, 0.26402702927589417, 0.1360737681388855, 0.098992720246315, 0.03493555635213852, 0.0, 0.0, 0.0, 0.0], [0.35578975081443787, 0.014380117878317833, 0.03903063386678696, 0.1461612582206726, 0.17310629785060883, 0.07869674265384674, 0.1549762487411499, 0.037858933210372925, 0.0, 0.0, 0.0], [0.6402668356895447, 0.002627457957714796, 0.018982289358973503, 0.08439154177904129, 0.08708323538303375, 0.018366781994700432, 0.06226572394371033, 0.06639587134122849, 0.019620265811681747, 0.0, 0.0], [0.8704294562339783, 0.004701536148786545, 0.005852213129401207, 0.01291540265083313, 0.012447213754057884, 0.006859704852104187, 0.007494715973734856, 0.030665945261716843, 0.030937792733311653, 0.01769603043794632, 0.0], [0.3157479166984558, 0.017331184819340706, 0.007081630639731884, 0.010885690338909626, 0.0033026982564479113, 0.0035276839043945074, 0.035482894629240036, 0.0008835591725073755, 0.00454025948420167, 0.5850176811218262, 0.016198839992284775]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9936641454696655, 0.006335853133350611, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9725344777107239, 0.012339599430561066, 0.015125902369618416, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9408213496208191, 0.020263494923710823, 0.01946253329515457, 0.019452614709734917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9073038101196289, 0.01575195975601673, 0.027571624144911766, 0.02229989506304264, 0.02707272209227085, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9183692336082458, 0.0076494356617331505, 0.027413656935095787, 0.014356144703924656, 0.021760256960988045, 0.010451272130012512, 0.0, 0.0, 0.0, 0.0, 0.0], [0.832650899887085, 0.010351533070206642, 0.05421005189418793, 0.026162082329392433, 0.032390985637903214, 0.016456319019198418, 0.02777811884880066, 0.0, 0.0, 0.0, 0.0], [0.9307627081871033, 0.016345584765076637, 0.004330535884946585, 0.0020061724353581667, 0.001957892207428813, 0.0023841809015721083, 0.019931921735405922, 0.02228102833032608, 0.0, 0.0, 0.0], [0.9787889719009399, 0.0020343575160950422, 0.0008950792835094035, 0.0009254750912077725, 0.0005960807320661843, 0.0005204029730521142, 0.001072146580554545, 0.005025925114750862, 0.01014153752475977, 0.0, 0.0], [0.8957326412200928, 0.0022727949544787407, 0.001726309536024928, 0.0014161799335852265, 0.0012578173773363233, 0.0014146229950711131, 0.0032405692618340254, 0.02901119366288185, 0.05057382956147194, 0.013353945687413216, 0.0], [0.9097650647163391, 0.005240941420197487, 0.0017760167829692364, 0.0012831224594265223, 0.0007376440917141736, 0.001526708365418017, 0.0032628909684717655, 0.003013000590726733, 0.0349300354719162, 0.015871962532401085, 0.022592589259147644]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9979978203773499, 0.0020021027885377407, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9987962245941162, 0.00022882303164806217, 0.0009748797165229917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9689155220985413, 0.016098126769065857, 0.0024556098505854607, 0.01253074873238802, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9691348075866699, 0.0033318125642836094, 0.0006770966574549675, 0.0005961943534202874, 0.02626008354127407, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9483001232147217, 0.00045379181392490864, 8.562365837860852e-05, 6.745444261468947e-05, 0.002544114366173744, 0.04854897782206535, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9914339780807495, 0.0010442881612107158, 0.00011899520904989913, 0.00018111339886672795, 0.00015258477651514113, 0.00023950466129463166, 0.006829512305557728, 0.0, 0.0, 0.0, 0.0], [0.9680391550064087, 0.014747929759323597, 0.0026130101177841425, 0.00029014915344305336, 0.0006094104028306901, 0.005789572838693857, 0.00619052117690444, 0.0017201779410243034, 0.0, 0.0, 0.0], [0.9985228180885315, 0.0004442223289515823, 0.00021085873595438898, 7.403941708616912e-05, 0.00010753527021734044, 0.00013402802869677544, 0.0003683285031002015, 4.316280683269724e-05, 9.498647705186158e-05, 0.0, 0.0], [0.9987088441848755, 0.00015478927525691688, 0.00032061003730632365, 5.718920874642208e-06, 1.0947449482046068e-05, 7.714244566159323e-05, 0.000300157000310719, 3.5418965126154944e-05, 5.4182462918106467e-05, 0.00033224921207875013, 0.0], [0.8867090344429016, 0.0026043104007840157, 0.0023567036259919405, 0.0006860969588160515, 0.0009989518439397216, 0.014764931052923203, 0.005942739080637693, 7.080255454638973e-05, 0.002027154201641679, 0.0014903456903994083, 0.08234889805316925]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9985276460647583, 0.001472284784540534, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.994520366191864, 0.0020765343215316534, 0.003403137670829892, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9738671183586121, 0.003456942969933152, 0.0017921801190823317, 0.020883845165371895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9922270774841309, 0.0020102602429687977, 0.0012630086857825518, 0.0007864308427087963, 0.0037132371217012405, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.98282790184021, 0.00034164570388384163, 0.00027313869213685393, 0.00010328964708605781, 0.0025671222247183323, 0.013886978849768639, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9815815687179565, 0.0008944175788201392, 0.0005548506742343307, 0.0008305887458845973, 0.00402107322588563, 0.001422598259523511, 0.010694955475628376, 0.0, 0.0, 0.0, 0.0], [0.9626479744911194, 0.00382247194647789, 0.007883293554186821, 0.0012204003287479281, 0.0036791986785829067, 0.001910721999593079, 0.006112911272794008, 0.012723062187433243, 0.0, 0.0, 0.0], [0.8392906188964844, 0.016776297241449356, 0.10901142656803131, 0.0035894436296075583, 0.012755445204675198, 0.0005183709436096251, 0.0071742944419384, 0.005485493689775467, 0.0053986674174666405, 0.0, 0.0], [0.9402751326560974, 0.0012481670128181577, 0.008047159761190414, 0.011375641450285912, 0.011550034396350384, 0.009783431887626648, 0.0071765766479074955, 0.0014246958307921886, 0.0006479661096818745, 0.008471143431961536, 0.0], [0.8990052342414856, 0.002819857094436884, 0.00885041244328022, 0.002887328388169408, 0.004314837511628866, 0.010219749063253403, 0.004671517759561539, 0.000702566874679178, 0.05596327781677246, 0.0070951865054667, 0.0034699407406151295]]], \"attentionHeadNames\": [\"L7H0\", \"L7H1\", \"L7H2\", \"L7H3\", \"L7H4\", \"L7H5\", \"L7H6\", \"L7H7\", \"L7H8\", \"L7H9\", \"L7H10\", \"L7H11\"], \"tokens\": [\"<|endoftext|>\", \"F\", \"illing\", \" up\", \" to\", \" eleven\", \" tokens\", \".\", \"\\n\", \"Go\", \".\"], \"maskUpperTri\": true}\n",
       "    )\n",
       "    </script></div><div style='max-width: 700px;'><h2>Layer 8 Logit Attribution Heads</h2><br/><div id=\"circuits-vis-1808888a-8f28\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionHeads } from \"https://unpkg.com/circuitsvis@1.41.0/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-1808888a-8f28\",\n",
       "      AttentionHeads,\n",
       "      {\"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9697210788726807, 0.030278954654932022, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.89847332239151, 0.04887017607688904, 0.052656449377536774, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8901073932647705, 0.031226228922605515, 0.028571870177984238, 0.05009445548057556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8498587608337402, 0.01822284422814846, 0.032914094626903534, 0.028441447764635086, 0.07056281715631485, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9135761857032776, 0.012305797077715397, 0.01933087222278118, 0.008473292924463749, 0.02448783814907074, 0.021826114505529404, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8770277500152588, 0.020556606352329254, 0.019228139892220497, 0.00824929028749466, 0.014355892315506935, 0.010997769422829151, 0.049584612250328064, 0.0, 0.0, 0.0, 0.0], [0.8644134402275085, 0.0157898161560297, 0.01834246516227722, 0.003794146701693535, 0.0026243089232593775, 0.00953354500234127, 0.010816183872520924, 0.07468613982200623, 0.0, 0.0, 0.0], [0.756439208984375, 0.05292671173810959, 0.034616805613040924, 0.018686430528759956, 0.004879589658230543, 0.03401860594749451, 0.010943400673568249, 0.038775138556957245, 0.048714183270931244, 0.0, 0.0], [0.8022440671920776, 0.015576248988509178, 0.009134323336184025, 0.011455086059868336, 0.011945156380534172, 0.015454523265361786, 0.0207211971282959, 0.047049861401319504, 0.03786826506257057, 0.028551284223794937, 0.0], [0.8138896226882935, 0.010467755608260632, 0.008122604340314865, 0.004404118750244379, 0.00536138704046607, 0.01161856111139059, 0.005394271574914455, 0.010249902494251728, 0.07874947786331177, 0.03189235180616379, 0.019850021228194237]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9988223910331726, 0.0011775369057431817, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9926764965057373, 0.002483928808942437, 0.004839584697037935, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9798796772956848, 0.007674246095120907, 0.00359639385715127, 0.008849723264575005, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9733448624610901, 0.0007817886653356254, 0.004058748949319124, 0.0014879992231726646, 0.0203265268355608, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9947537183761597, 0.0003529540845192969, 0.00045041210250929, 0.00016460602637380362, 0.0030711935833096504, 0.0012071069795638323, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9789930582046509, 0.0008813877939246595, 0.003965208772569895, 0.0016954065067693591, 0.00463436683639884, 0.0014913268387317657, 0.008339230902493, 0.0, 0.0, 0.0, 0.0], [0.9549630880355835, 0.012808924540877342, 0.017784710973501205, 0.001811823807656765, 0.0030480928253382444, 0.0030561278108507395, 0.0042756046168506145, 0.0022515365853905678, 0.0, 0.0, 0.0], [0.9927256107330322, 0.000935134943574667, 0.001376815140247345, 0.0004834562714677304, 0.0014530123444274068, 0.0012398051330819726, 0.0013946538092568517, 0.00020520316320471466, 0.0001862539502326399, 0.0, 0.0], [0.9853799939155579, 0.0003624780219979584, 0.0039759185165166855, 0.0007605632999911904, 0.0024261227808892727, 0.005078097339719534, 0.0004732020606752485, 0.0004871724231634289, 0.0004733544192276895, 0.0005830101436004043, 0.0], [0.9388698935508728, 0.007300783880054951, 0.003966257441788912, 0.0006558363093063235, 0.0022957560140639544, 0.004340165760368109, 0.0010425745276734233, 6.963300984352827e-05, 0.01365173701196909, 0.004581432323902845, 0.023225931450724602]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.996167004108429, 0.003832933260127902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.962202250957489, 0.010482779704034328, 0.027315029874444008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9273866415023804, 0.012378587387502193, 0.025243539363145828, 0.034991245716810226, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9596384763717651, 0.006374057848006487, 0.006217184942215681, 0.008718238212168217, 0.019051991403102875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7066135406494141, 0.002711079316213727, 0.006083865184336901, 0.005137198604643345, 0.008936598896980286, 0.2705177366733551, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7297248244285583, 0.006792714353650808, 0.016514161601662636, 0.010219844058156013, 0.02326914295554161, 0.06110331788659096, 0.15237604081630707, 0.0, 0.0, 0.0, 0.0], [0.6604401469230652, 0.010234273038804531, 0.025042984634637833, 0.02019858919084072, 0.042193252593278885, 0.04251500591635704, 0.14854732155799866, 0.05082842335104942, 0.0, 0.0, 0.0], [0.6874793767929077, 0.0015024264575913548, 0.0010113934986293316, 0.005983853247016668, 0.0048484052531421185, 0.1940605491399765, 0.06825780123472214, 0.023587238043546677, 0.013268999755382538, 0.0, 0.0], [0.7329903841018677, 0.009464175440371037, 0.011966931633651257, 0.016982773318886757, 0.02598516456782818, 0.029622796922922134, 0.0556480847299099, 0.06257053464651108, 0.034296151250600815, 0.020472904667258263, 0.0], [0.8026769161224365, 0.015468866564333439, 0.014385536313056946, 0.011750312522053719, 0.018479829654097557, 0.006794374901801348, 0.025646314024925232, 0.012343610636889935, 0.0210417453199625, 0.013253708370029926, 0.058158744126558304]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9921425580978394, 0.007857494987547398, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9770857095718384, 0.014848421327769756, 0.008065789937973022, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9860031604766846, 0.008882795460522175, 0.0033731532748788595, 0.0017409457359462976, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9474892020225525, 0.018657371401786804, 0.014660395681858063, 0.006721844431012869, 0.012471172958612442, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9694371819496155, 0.012437098659574986, 0.0059319534339010715, 0.004334656987339258, 0.0019715474918484688, 0.005887458100914955, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9502791166305542, 0.0113392798230052, 0.006577009800821543, 0.0018166694790124893, 0.002569279633462429, 0.0024863306898623705, 0.024932289496064186, 0.0, 0.0, 0.0, 0.0], [0.8681432604789734, 0.03377700597047806, 0.015361680649220943, 0.0025741190183907747, 0.005842289421707392, 0.003998952452093363, 0.034213270992040634, 0.036089472472667694, 0.0, 0.0, 0.0], [0.9159941077232361, 0.04545116424560547, 0.007502473425120115, 0.0010485805105417967, 0.0017537609674036503, 0.0017591662472113967, 0.008762776851654053, 0.0072626229375600815, 0.01046541053801775, 0.0, 0.0], [0.9413041472434998, 0.017366869375109673, 0.0043345121666789055, 0.0010086267720907927, 0.0013917823089286685, 0.0016068064142018557, 0.005006155930459499, 0.01392750907689333, 0.007915670052170753, 0.006137933116406202, 0.0], [0.6600989699363708, 0.0138440215960145, 0.009509844705462456, 0.006143754348158836, 0.005290919449180365, 0.006156056188046932, 0.018474318087100983, 0.022975871339440346, 0.01239639613777399, 0.04691832512617111, 0.19819137454032898]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9991515874862671, 0.0008484668214805424, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7670873999595642, 0.02544381283223629, 0.20746876299381256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8831164836883545, 0.010147320106625557, 0.047431591898202896, 0.05930459499359131, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.420389860868454, 0.0025556788314133883, 0.06535164266824722, 0.283265084028244, 0.22843770682811737, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5594191551208496, 0.005276367999613285, 0.15243934094905853, 0.14839206635951996, 0.12375543266534805, 0.010717642493546009, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5679260492324829, 0.0033907333854585886, 0.11268331110477448, 0.09821455180644989, 0.06951087713241577, 0.10979244112968445, 0.03848209232091904, 0.0, 0.0, 0.0, 0.0], [0.9436432123184204, 0.006565760355442762, 0.001666623866185546, 0.0009252158342860639, 0.0007411562837660313, 0.0037131309509277344, 0.015026552602648735, 0.02771829254925251, 0.0, 0.0, 0.0], [0.9537447094917297, 0.0005285002989694476, 0.0003275801718700677, 0.000993251451291144, 0.0005342687945812941, 0.0016955580795183778, 0.012435652315616608, 0.01713128387928009, 0.012609285302460194, 0.0, 0.0], [0.9288049936294556, 0.000436735077528283, 0.0009256573393940926, 0.0025076691526919603, 0.004549235105514526, 0.0025145639665424824, 0.01503414660692215, 0.017348002642393112, 0.012418392114341259, 0.015460600145161152, 0.0], [0.8241775035858154, 0.0015305361011996865, 0.0017184966709464788, 0.0016508727567270398, 0.0005582322482950985, 0.0010404479689896107, 0.003767595160752535, 0.0025675916112959385, 0.017723284661769867, 0.09833891689777374, 0.04692657291889191]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9891948699951172, 0.010805117897689342, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8228095173835754, 0.1599075049161911, 0.017282988876104355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7786924242973328, 0.08461574465036392, 0.10166483372449875, 0.035027023404836655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7803361415863037, 0.08186722546815872, 0.04575368016958237, 0.049344055354595184, 0.042698927223682404, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6796581149101257, 0.017643120139837265, 0.06857455521821976, 0.09814199805259705, 0.08426836878061295, 0.051713909953832626, 0.0, 0.0, 0.0, 0.0, 0.0], [0.49942535161972046, 0.019197694957256317, 0.10604413598775864, 0.10818157345056534, 0.061271294951438904, 0.1347682923078537, 0.07111157476902008, 0.0, 0.0, 0.0, 0.0], [0.6549072861671448, 0.023094091564416885, 0.012173076160252094, 0.020265774801373482, 0.024242399260401726, 0.07966067641973495, 0.08114632219076157, 0.10451032221317291, 0.0, 0.0, 0.0], [0.9192668795585632, 0.004725855775177479, 0.0008886278374120593, 0.003209482179954648, 0.0029386465903371572, 0.008699517697095871, 0.021821163594722748, 0.021041549742221832, 0.01740831881761551, 0.0, 0.0], [0.7958638668060303, 0.008972859010100365, 0.004535546991974115, 0.006463250145316124, 0.00857717078179121, 0.006649246904999018, 0.009508746676146984, 0.031199539080262184, 0.09894097596406937, 0.02928886003792286, 0.0], [0.6234117746353149, 0.009359974414110184, 0.006506997160613537, 0.006779963616281748, 0.009450359269976616, 0.005586777813732624, 0.009637347422540188, 0.013382847420871258, 0.061170659959316254, 0.13175977766513824, 0.12295351922512054]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9879654049873352, 0.012034613639116287, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9546125531196594, 0.002643725834786892, 0.042743705213069916, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.888420820236206, 0.00441750418394804, 0.04514409229159355, 0.06201748922467232, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8530740141868591, 0.01338875200599432, 0.02751285582780838, 0.07132602483034134, 0.03469833359122276, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9782213568687439, 0.0032340558245778084, 0.003737421939149499, 0.002367848763242364, 0.0027073731180280447, 0.00973186269402504, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9456842541694641, 0.013671132735908031, 0.006444997154176235, 0.0027056699618697166, 0.005699842236936092, 0.002553253434598446, 0.023240935057401657, 0.0, 0.0, 0.0, 0.0], [0.6144800186157227, 0.052056796848773956, 0.14699450135231018, 0.058811452239751816, 0.03750953823328018, 0.005831460934132338, 0.018248721957206726, 0.06606744229793549, 0.0, 0.0, 0.0], [0.8982892036437988, 0.01273143757134676, 0.02435624785721302, 0.017942719161510468, 0.01463928259909153, 0.004790989216417074, 0.005712196230888367, 0.011642327532172203, 0.009895614348351955, 0.0, 0.0], [0.7236673831939697, 0.005039241164922714, 0.03512373939156532, 0.05520271509885788, 0.03374842181801796, 0.010535655543208122, 0.01699245721101761, 0.07870866358280182, 0.013716378249228, 0.027265271171927452, 0.0], [0.5645803809165955, 0.024838007986545563, 0.07379770278930664, 0.09158729761838913, 0.01895437017083168, 0.003060273826122284, 0.004834226332604885, 0.0019790218211710453, 0.007636102847754955, 0.08717567473649979, 0.12155691534280777]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9774035215377808, 0.022596392780542374, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9012496471405029, 0.01975000835955143, 0.0790003314614296, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6026500463485718, 0.012611670419573784, 0.22528816759586334, 0.15945012867450714, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4923824071884155, 0.004916452802717686, 0.06742073595523834, 0.25513285398483276, 0.18014748394489288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04813945293426514, 0.001954448875039816, 0.216758131980896, 0.5875524878501892, 0.13069993257522583, 0.014895523898303509, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17799371480941772, 0.0021671459544450045, 0.08512751758098602, 0.4418494999408722, 0.1425987333059311, 0.11974480748176575, 0.030518585816025734, 0.0, 0.0, 0.0, 0.0], [0.8774679899215698, 0.006767174229025841, 0.006881277542561293, 0.007841448299586773, 0.00593543378636241, 0.026061126962304115, 0.051629044115543365, 0.017416492104530334, 0.0, 0.0, 0.0], [0.8526656031608582, 0.0035205730237066746, 0.002717700321227312, 0.0073579661548137665, 0.0069914935156702995, 0.024315765127539635, 0.04163573309779167, 0.025805579498410225, 0.034989602863788605, 0.0, 0.0], [0.8470040559768677, 0.010793601162731647, 0.0008163086022250354, 0.001570574240759015, 0.005451521370559931, 0.009917199611663818, 0.005915957037359476, 0.04207157343626022, 0.06791730225086212, 0.008541956543922424, 0.0], [0.641549825668335, 0.005366883706301451, 0.015317090786993504, 0.01811600662767887, 0.007936904206871986, 0.006876280065625906, 0.006083036307245493, 0.00185754569247365, 0.00925834197551012, 0.2601238191127777, 0.027514275163412094]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9902273416519165, 0.009772619232535362, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9519467353820801, 0.010054747574031353, 0.03799853101372719, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8755953311920166, 0.005795754492282867, 0.025190379470586777, 0.09341854602098465, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7689282298088074, 0.016219282522797585, 0.030357353389263153, 0.08948782086372375, 0.09500722587108612, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7852863669395447, 0.011634503491222858, 0.0278939176350832, 0.09923503547906876, 0.06383199989795685, 0.012118188664317131, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7811928391456604, 0.0032092053443193436, 0.03850596025586128, 0.03227347508072853, 0.04244295507669449, 0.013162259943783283, 0.08921335637569427, 0.0, 0.0, 0.0, 0.0], [0.6213200688362122, 0.006400687620043755, 0.02074209414422512, 0.02255438081920147, 0.03403455764055252, 0.009992895647883415, 0.18491700291633606, 0.1000383049249649, 0.0, 0.0, 0.0], [0.9011535048484802, 0.0050127762369811535, 0.003098944202065468, 0.003534349612891674, 0.0047107296995818615, 0.003980637528002262, 0.03707356005907059, 0.032860469073057175, 0.008575060404837132, 0.0, 0.0], [0.685512900352478, 0.004156921990215778, 0.009362516924738884, 0.017776796594262123, 0.02560867927968502, 0.010697501711547375, 0.09045543521642685, 0.0770978331565857, 0.056286606937646866, 0.023044779896736145, 0.0], [0.6857451796531677, 0.009276180528104305, 0.01770952343940735, 0.031264904886484146, 0.03830075263977051, 0.020633215084671974, 0.03755167871713638, 0.01365811750292778, 0.010844839736819267, 0.08955072611570358, 0.0454648919403553]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9924020767211914, 0.007597886957228184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8976475596427917, 0.014396286569535732, 0.08795608580112457, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9166138768196106, 0.007338254246860743, 0.03446822986006737, 0.04157967492938042, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8694146275520325, 0.006997918244451284, 0.045635707676410675, 0.04895694553852081, 0.028994817286729813, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8990353941917419, 0.0024938159622251987, 0.020766638219356537, 0.039786260575056076, 0.016868719831109047, 0.021049045026302338, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8000082969665527, 0.0031187504064291716, 0.027097325772047043, 0.0545659177005291, 0.020862702280282974, 0.015521100722253323, 0.07882586866617203, 0.0, 0.0, 0.0, 0.0], [0.6113135814666748, 0.005300352815538645, 0.05304974690079689, 0.05964098870754242, 0.0321832150220871, 0.06293956190347672, 0.09874320775270462, 0.07682939618825912, 0.0, 0.0, 0.0], [0.7635198831558228, 0.005480758845806122, 0.028781326487660408, 0.019106902182102203, 0.008848091587424278, 0.018440335988998413, 0.04513521119952202, 0.0744282528758049, 0.03625926002860069, 0.0, 0.0], [0.8284742832183838, 0.002332446165382862, 0.016781412065029144, 0.008584939874708652, 0.007489900104701519, 0.014774489216506481, 0.03706929832696915, 0.05487784743309021, 0.012690660543739796, 0.01692471280694008, 0.0], [0.72066330909729, 0.00476984353736043, 0.01869453489780426, 0.0172932967543602, 0.007785390131175518, 0.011512312106788158, 0.032252855598926544, 0.023096879944205284, 0.020855499431490898, 0.06108393147587776, 0.08199214190244675]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9751987457275391, 0.024801285937428474, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9645349979400635, 0.009243495762348175, 0.026221534237265587, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.920079231262207, 0.017109287902712822, 0.022901790216565132, 0.039909712970256805, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8143013119697571, 0.02839479222893715, 0.04878011718392372, 0.039296653121709824, 0.0692272037267685, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8551781177520752, 0.024932313710451126, 0.027622831985354424, 0.022026188671588898, 0.036952853202819824, 0.0332876481115818, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7747365236282349, 0.008478528819978237, 0.033505771309137344, 0.021535785868763924, 0.020493142306804657, 0.00841745175421238, 0.13283288478851318, 0.0, 0.0, 0.0, 0.0], [0.7510624527931213, 0.03258223459124565, 0.034141071140766144, 0.011981312185525894, 0.008741614408791065, 0.009844258427619934, 0.06380479782819748, 0.08784234523773193, 0.0, 0.0, 0.0], [0.76291823387146, 0.036463603377342224, 0.022712022066116333, 0.007789249066263437, 0.00836886279284954, 0.010336803272366524, 0.023651162162423134, 0.0505080446600914, 0.07725194096565247, 0.0, 0.0], [0.8738284707069397, 0.011210680939257145, 0.008370563387870789, 0.008090328425168991, 0.006922823376953602, 0.003977784886956215, 0.021527595818042755, 0.022733906283974648, 0.01766815595328808, 0.025669820606708527, 0.0], [0.6320905685424805, 0.016265347599983215, 0.013380794785916805, 0.013002806343138218, 0.011750616133213043, 0.006972558330744505, 0.019598860293626785, 0.040423743426799774, 0.07451166212558746, 0.11395993083715439, 0.05804314836859703]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9891378283500671, 0.01086221169680357, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9610258340835571, 0.03484459966421127, 0.004129488952457905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9578076601028442, 0.022360973060131073, 0.01010679267346859, 0.00972447544336319, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9545297622680664, 0.01099273283034563, 0.010339586064219475, 0.014478454366326332, 0.009659568779170513, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9653281569480896, 0.007484488654881716, 0.008335289545357227, 0.011749706231057644, 0.004604789428412914, 0.0024976138956844807, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9407722353935242, 0.004763386212289333, 0.005914004053920507, 0.008157155476510525, 0.003006760962307453, 0.012270819395780563, 0.025115778669714928, 0.0, 0.0, 0.0, 0.0], [0.8116297125816345, 0.014061957597732544, 0.007555797230452299, 0.0056369733065366745, 0.0025070253759622574, 0.03019472397863865, 0.10119445621967316, 0.027219409123063087, 0.0, 0.0, 0.0], [0.9153682589530945, 0.013313297182321548, 0.0034265604335814714, 0.001961918082088232, 0.0013938862830400467, 0.008016538806259632, 0.04030592739582062, 0.01092586014419794, 0.005287695210427046, 0.0, 0.0], [0.9012213349342346, 0.013994429260492325, 0.003350016428157687, 0.0026166399475187063, 0.0021218883339315653, 0.00880381464958191, 0.043476227670907974, 0.006717044394463301, 0.007009875029325485, 0.010688711889088154, 0.0], [0.7665132880210876, 0.023437656462192535, 0.012207401916384697, 0.008968492969870567, 0.0016053763683885336, 0.024190308526158333, 0.023677883669734, 0.008469952270388603, 0.0059500448405742645, 0.10398489981889725, 0.02099466882646084]]], \"attentionHeadNames\": [\"L8H0\", \"L8H1\", \"L8H2\", \"L8H3\", \"L8H4\", \"L8H5\", \"L8H6\", \"L8H7\", \"L8H8\", \"L8H9\", \"L8H10\", \"L8H11\"], \"tokens\": [\"<|endoftext|>\", \"F\", \"illing\", \" up\", \" to\", \" eleven\", \" tokens\", \".\", \"\\n\", \"Go\", \".\"], \"maskUpperTri\": true}\n",
       "    )\n",
       "    </script></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = 3\n",
    "\n",
    "top_positive_logit_attr_heads = torch.topk(\n",
    "    per_head_logit_diffs.flatten(), k=top_k\n",
    ").indices\n",
    "\n",
    "html = \"\"\n",
    "for layer in range(5, 9):\n",
    "    heads = range(layer*model.cfg.n_heads, (layer+1)*model.cfg.n_heads)\n",
    "\n",
    "    html += visualize_attention_patterns(\n",
    "        heads,\n",
    "        cache,\n",
    "        tokens[0],\n",
    "        f\"Layer {layer} Logit Attribution Heads\",\n",
    "    )\n",
    "\n",
    "HTML(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "- Not seeing any evidence of attention paid to F by fullstop in layers 6-8...\n",
    "\n",
    "- Missing something."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
